<!DOCTYPE html>
<!--suppress ALL -->
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>mathematical modeling</title>
    <link href="../static/css/code.css" rel="stylesheet" type="text/css">
    <style>
        .tit{
            text-align:center;
        }
        div{
            font-size:20px;
        }
        a:link {color: black}
        a:visited {color: black}
        a:hover {color: black}
        a:active {color: black}
    </style>
    <base target="_blank">
</head>
<body>
    <div class="tit">
        <span style="color:red;font-size:40px;">曲线拟合问题</span>
    </div>
    <ol type="I">
        <li>
            <div>这里由于没有数据，先生成实验数据</div>
            <div>首先目标曲线：</div>
            <div><img src="../static/Math/mathematicalModeling/1.png"></div>
            <div><img src="../static/Math/mathematicalModeling/2.png"></div>
            <div>生成曲线数据方法如下：</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>from scipy.stats import norm</code></span>
                <span><code></code></span>
                <span><code>def function(x, a , b, f, phi):</code></span>
                <span><code>    result = a * np.exp(-b * np.sin(f * x + phi))</code></span>
                <span><code>    return result</code></span>
                <span><code></code></span>
                <span><code>x = np.linspace(0, 2 * np.pi, 50)</code></span>
                <span><code>actual_parameters = [3, 2, 1.25, np.pi / 4]</code></span>
                <span><code>y = function(x, *actual_parameters)</code></span>
                <span><code>y_noisy = y + 0.8 * norm.rvs(size=len(x))</code></span>
            </pre>
            <div>生成数据如下：</div>
            <table border="4">
                <tr>
                    <th>X</th>
                    <th>y</th>
                </tr>
                <tr>
                    <td>0.2236457993127439</td>
                    <td>0.0</td>
                </tr>
                <tr>
                    <td>1.4472239795989474</td>
                    <td>0.1282282715750936</td>
                </tr>
                <tr>
                    <td>1.5792959120790648</td>
                    <td>0.2564565431501872</td>
                </tr>
                <tr>
                    <td>0.6778526748445148</td>
                    <td>0.3846848147252807</td>
                </tr>
                <tr>
                    <td>-0.6797746530946486</td>
                    <td>0.5129130863003744</td>
                </tr>
                <tr>
                    <td>-1.345488810309232</td>
                    <td>0.6411413578754679</td>
                </tr>
                <tr>
                    <td>0.4305698669877983</td>
                    <td>0.7693696294505615</td>
                </tr>
                <tr>
                    <td>0.2225439327873096</td>
                    <td>0.8975979010256552</td>
                </tr>
                <tr>
                    <td>0.5563458625209984</td>
                    <td>1.0258261726007487</td>
                </tr>
                <tr>
                    <td>0.9735430216325486</td>
                    <td>1.1540544441758422</td>
                </tr>
                <tr>
                    <td>1.6505242044568138</td>
                    <td>1.2822827157509358</td>
                </tr>
                <tr>
                    <td>2.2295451677583267</td>
                    <td>1.4105109873260295</td>
                </tr>
                <tr>
                    <td>1.628960353649783</td>
                    <td>1.538739258901123</td>
                </tr>
                <tr>
                    <td>0.9288338406419172</td>
                    <td>1.6669675304762166</td>
                </tr>
                <tr>
                    <td>2.2110209441001736</td>
                    <td>1.7951958020513104</td>
                </tr>
                <tr>
                    <td>3.999369944623464</td>
                    <td>1.923424073626404</td>
                </tr>
                <tr>
                    <td>3.9376386726741193</td>
                    <td>2.0516523452014974</td>
                </tr>
                <tr>
                    <td>4.657941910308808</td>
                    <td>2.179880616776591</td>
                </tr>
                <tr>
                    <td>7.331812028544913</td>
                    <td>2.3081088883516845</td>
                </tr>
                <tr>
                    <td>9.774651123767196</td>
                    <td>2.436337159926778</td>
                </tr>
                <tr>
                    <td>13.072575654860648</td>
                    <td>2.564565431501872</td>
                </tr>
                <tr>
                    <td>16.046094983549896</td>
                    <td>2.692793703076965</td>
                </tr>
                <tr>
                    <td>18.481085161260022</td>
                    <td>2.821021974652059</td>
                </tr>
                <tr>
                    <td>19.58699050741213</td>
                    <td>2.9492502462271526</td>
                </tr>
                <tr>
                    <td>22.04319094067442</td>
                    <td>3.077478517802246</td>
                </tr>
                <tr>
                    <td>22.02385348945999</td>
                    <td>3.20570678937734</td>
                </tr>
                <tr>
                    <td>20.503432658529263</td>
                    <td>3.333935060952433</td>
                </tr>
                <tr>
                    <td>18.85461977186076</td>
                    <td>3.4621633325275267</td>
                </tr>
                <tr>
                    <td>16.802089091952716</td>
                    <td>3.5903916041026207</td>
                </tr>
                <tr>
                    <td>13.11532042210773</td>
                    <td>3.718619875677714</td>
                </tr>
                <tr>
                    <td>11.297549961853283</td>
                    <td>3.846848147252808</td>
                </tr>
                <tr>
                    <td>7.747740727077016</td>
                    <td>3.975076418827901</td>
                </tr>
                <tr>
                    <td>5.728927390707121</td>
                    <td>4.103304690402995</td>
                </tr>
                <tr>
                    <td>5.125876657542555</td>
                    <td>4.231532961978089</td>
                </tr>
                <tr>
                    <td>3.378692145170281</td>
                    <td>4.359761233553182</td>
                </tr>
                <tr>
                    <td>2.7147610622780087</td>
                    <td>4.487989505128276</td>
                </tr>
                <tr>
                    <td>2.305721533048369</td>
                    <td>4.616217776703369</td>
                </tr>
                <tr>
                    <td>0.8972099977883041</td>
                    <td>4.744446048278463</td>
                </tr>
                <tr>
                    <td>-0.1996605132227342</td>
                    <td>4.872674319853556</td>
                </tr>
                <tr>
                    <td>1.243082834436828</td>
                    <td>5.00090259142865</td>
                </tr>
                <tr>
                    <td>-0.1275325117242889</td>
                    <td>5.129130863003743</td>
                </tr>
                <tr>
                    <td>1.0871655290227444</td>
                    <td>5.257359134578837</td>
                </tr>
                <tr>
                    <td>-0.7857412983994341</td>
                    <td>5.385587406153931</td>
                </tr>
                <tr>
                    <td>0.7708997393738456</td>
                    <td>5.513815677729024</td>
                </tr>
                <tr>
                    <td>0.6419152273260361</td>
                    <td>5.642043949304118</td>
                </tr>
                <tr>
                    <td>-0.2359115509562813</td>
                    <td>5.770272220879211</td>
                </tr>
                <tr>
                    <td>0.443110821073647</td>
                    <td>5.898500492454305</td>
                </tr>
                <tr>
                    <td>1.4139827980946416</td>
                    <td>6.026728764029398</td>
                </tr>
                <tr>
                    <td>0.6262415653904855</td>
                    <td>6.154957035604492</td>
                </tr>
                <tr>
                    <td>1.1785639400214245</td>
                    <td>6.283185307179586</td>
                </tr>
            </table>
            <div><img src="../static/Math/mathematicalModeling/3.png"></div>
        </li>
        <li>
            <div>最小二乘法拟合</div>
            <pre id="code_block">
                <span><code>from scipy.optimize import curve_fit</code></span>
                <span><code>p_est,err_est = curve_fit(function, x, y_noisy)</code></span>
                <span><code>print(p_est)</code></span>
            </pre>
            <div>我们得到了系数的解</div>
            <table border="4">
                <tr>
                    <th>参数</th>
                    <th>计算得到的</th>
                    <th>原函数</th>
                </tr>
                <tr>
                    <td>a</td>
                    <td>3.12367656</td>
                    <td>3</td>
                </tr>
                <tr>
                    <td>b</td>
                    <td>1.9478261</td>
                    <td>2</td>
                </tr>
                <tr>
                    <td>f</td>
                    <td>1.28744683</td>
                    <td>1.25</td>
                </tr>
                <tr>
                    <td>phi</td>
                    <td>0.6444031</td>
                    <td>0.7853981</td>
                </tr>
            </table>
            <div><img src="../static/Math/mathematicalModeling/4.png"></div>
        </li>
        <li>
            <div>误差分析</div>
            <pre id="code_block">
                <span><code>print(err_est)</code></span>
            </pre>
            <div>可以得到协方差矩阵</div>
            <img src="../static/Math/mathematicalModeling/5.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">Lagrange乘数法</span>
    </div>
    <ol type="I">
        <li>
            <div>这里由于没有数据，先生成实验数据</div>
            <div>生成曲线数据方法如下：</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code></code></span>
                <span><code>x = np.linspace(0,5,10)</code></span>
                <span><code>y = 2*x</code></span>
                <span><code>r = np.random.RandomState(42)</code></span>
                <span><code>y += r.randn(10)</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/6.png"></div>
        </li>
        <li>
            <div>Lagrange乘数法的实现</div>
            <pre id="code_block">
                <span><code>def p(args, ex):</code></span>
                <span><code>    def loop(largs):</code></span>
                <span><code>        if len(largs) == 1: return [1, -largs[0]]</code></span>
                <span><code>        dp = loop(largs[1:])</code></span>
                <span><code>        return [-largs[0] * i + j for i, j in zip([0] + dp, dp + [0])]</code></span>
                <span><code></code></span>
                <span><code>    largs = list(args)</code></span>
                <span><code>    largs.remove(ex)</code></span>
                <span><code>    div = 1</code></span>
                <span><code>    for i in largs:</code></span>
                <span><code>        div *= ex[0] - i[0]</code></span>
                <span><code>    return [i * ex[1] / div for i in loop(list(zip(*largs))[0])]</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>def Lagrange(*args):</code></span>
                <span><code>    lists = [p(args, i) for i in args]</code></span>
                <span><code>    ans = [sum(i) for i in zip(*lists)]</code></span>
                <span><code>    ans.reverse()</code></span>
                <span><code></code></span>
                <span><code>    def rtn_func(x):</code></span>
                <span><code>        return sum([a * x ** i for i, a in enumerate(ans)])</code></span>
                <span><code></code></span>
                <span><code>    return rtn_func</code></span>
            </pre>
        </li>
        <li>
            <div>拟合分析</div>
            <pre id="code_block">
                <span><code>func = Lagrange(*zip(x, y))</code></span>
                <span><code>x = np.arange(0, 5.1, 0.1)</code></span>
                <span><code>y = [func(i) for i in x]</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/7.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">退火算法</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解：</div>
            <div style="text-indent:2em;">假设前一个状态为x(n),系统根据某一指标（梯度下降，上节的能量），状态变为x(n+1),相应的，系统的能量由E(n)变为E(n+1),定义系统由x(n)变为x(n+1)的接受概率P为：</div>
            <div><img src="../static/Math/mathematicalModeling/8.png"></div>

            <div style="text-indent:2em;">从上式我们可以看到，如果能量减小了，那么这种转移就被接受（概率为1），如果能量增大了，就说明系统偏离全局最优值位置更远了，此时算法不会立刻将其抛弃，而是进行概率操作：首先在区间【0,1】产生一个均匀分布的随机数ϵ，如果ϵ&lt;P，则此种转移接受，否则拒绝转移，进入下一步，往复循环。其中P以能量的变化量和T进行决定概率P的大小，所以这个值是动态的。</div>
            <div style="text-indent:2em;">用固体退火模拟组合优化问题，将内能E模拟为目标函数值f，温度T演化成控制参数t，即得到解组合优化问题的模拟退火算法：由初始解i和控制参数初值t开始，对当前解重复“产生新解→计算目标函数差→接受或舍弃”的迭代，并逐步衰减t值，算法终止时的当前解即为所得近似最优解，退火过程由冷却进度表(Cooling Schedule)控制，包括控制参数的初值t及其衰减因子Δt、每个t值时的迭代次数L和停止条件Tf。而温度的作用就是来计算转移概率P的。当温度每次下降后，转移概率也发生变化，因此在所有温度下迭代L次的结果也都是不相同的。在每个温度下迭代L次来寻找当前温度下的最优解，然后降低温度继续寻找，直到到达终止温度，即转移概率P接近于0</div>
            <div style="text-indent:2em;">接受状态的三条原则：</div>
            <ol style="1">
                <li>在固定温度下，接受使目标函数下降的候选解的概率要大于使目标函数上升的候选解概率；</li>
                <li>随着温度的下降，接受使目标函数上升的解的概率要逐渐减小；</li>
                <li>当温度趋于零时，只能接受目标函数下降的解。</li>
            </ol>
        </li>
        <li>
            <div>流程分析</div>
            <div><img src="../static/Math/mathematicalModeling/9.png"></div>
        </li>
        <li>
            <div>代码实现</div>
            <div><img src="../static/Math/mathematicalModeling/10.png"></div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>from random import random</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>def func(x, y):  # 函数优化问题</code></span>
                <span><code>    res = 4 * x ** 2 - 2.1 * x ** 4 + x ** 6 / 3 + x * y - 4 * y ** 2 + 4 * y ** 4</code></span>
                <span><code>    return res</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code># x为公式里的x1,y为公式里面的x2</code></span>
                <span><code>class SA:</code></span>
                <span><code>    def __init__(self, func, iter=100, T0=100, Tf=0.01, alpha=0.99):</code></span>
                <span><code>        self.func = func</code></span>
                <span><code>        self.iter = iter  # 内循环迭代次数,即为L =100</code></span>
                <span><code>        self.alpha = alpha  # 降温系数，alpha=0.99</code></span>
                <span><code>        self.T0 = T0  # 初始温度T0为100</code></span>
                <span><code>        self.Tf = Tf  # 温度终值Tf为0.01</code></span>
                <span><code>        self.T = T0  # 当前温度</code></span>
                <span><code>        self.x = [random() * 11 - 5 for i in range(iter)]  # 随机生成100个x的值</code></span>
                <span><code>        self.y = [random() * 11 - 5 for i in range(iter)]  # 随机生成100个y的值</code></span>
                <span><code>        self.most_best = []</code></span>
                <span><code>        """</code></span>
                <span><code>        random()这个函数取0到1之间的小数</code></span>
                <span><code>        如果你要取0-10之间的整数（包括0和10）就写成 (int)random()*11就可以了，11乘以零点多的数最大是10点多，最小是0点多</code></span>
                <span><code>        该实例中x1和x2的绝对值不超过5（包含整数5和-5），（random() * 11 -5）的结果是-6到6之间的任意值（不包括-6和6）</code></span>
                <span><code>        （random() * 10 -5）的结果是-5到5之间的任意值（不包括-5和5），所有先乘以11，取-6到6之间的值，产生新解过程中，用一个if条件语句把-5到5之间（包括整数5和-5）的筛选出来。</code></span>
                <span><code>        """</code></span>
                <span><code>        self.history = {'f': [], 'T': []}</code></span>
                <span><code></code></span>
                <span><code>    def generate_new(self, x, y):  # 扰动产生新解的过程</code></span>
                <span><code>        while True:</code></span>
                <span><code>            x_new = x + self.T * (random() - random())</code></span>
                <span><code>            y_new = y + self.T * (random() - random())</code></span>
                <span><code>            if (-5 <= x_new <= 5) & (-5 <= y_new <= 5):</code></span>
                <span><code>                break  # 重复得到新解，直到产生的新解满足约束条件</code></span>
                <span><code>        return x_new, y_new</code></span>
                <span><code></code></span>
                <span><code>    def Metrospolis(self, f, f_new):  # Metropolis准则</code></span>
                <span><code>        if f_new <= f:</code></span>
                <span><code>            return 1</code></span>
                <span><code>        else:</code></span>
                <span><code>            p = np.exp((f - f_new) / self.T)</code></span>
                <span><code>            if random() < p:</code></span>
                <span><code>                return 1</code></span>
                <span><code>            else:</code></span>
                <span><code>                return 0</code></span>
                <span><code></code></span>
                <span><code>    def best(self):  # 获取最优目标函数值</code></span>
                <span><code>        f_list = []  # f_list数组保存每次迭代之后的值</code></span>
                <span><code>        for i in range(self.iter):</code></span>
                <span><code>            f = self.func(self.x[i], self.y[i])</code></span>
                <span><code>            f_list.append(f)</code></span>
                <span><code>        f_best = min(f_list)</code></span>
                <span><code></code></span>
                <span><code>        idx = f_list.index(f_best)</code></span>
                <span><code>        return f_best, idx  # f_best,idx分别为在该温度下，迭代L次之后目标函数的最优解和最优解的下标</code></span>
                <span><code></code></span>
                <span><code>    def run(self):</code></span>
                <span><code>        count = 0</code></span>
                <span><code>        # 外循环迭代，当前温度小于终止温度的阈值</code></span>
                <span><code>        while self.T > self.Tf:</code></span>
                <span><code></code></span>
                <span><code>            # 内循环迭代100次</code></span>
                <span><code>            for i in range(self.iter):</code></span>
                <span><code>                f = self.func(self.x[i], self.y[i])  # f为迭代一次后的值</code></span>
                <span><code>                x_new, y_new = self.generate_new(self.x[i], self.y[i])  # 产生新解</code></span>
                <span><code>                f_new = self.func(x_new, y_new)  # 产生新值</code></span>
                <span><code>                if self.Metrospolis(f, f_new):  # 判断是否接受新值</code></span>
                <span><code>                    self.x[i] = x_new  # 如果接受新值，则把新值的x,y存入x数组和y数组</code></span>
                <span><code>                    self.y[i] = y_new</code></span>
                <span><code>            # 迭代L次记录在该温度下最优解</code></span>
                <span><code>            ft, _ = self.best()</code></span>
                <span><code>            self.history['f'].append(ft)</code></span>
                <span><code>            self.history['T'].append(self.T)</code></span>
                <span><code>            # 温度按照一定的比例下降（冷却）</code></span>
                <span><code>            self.T = self.T * self.alpha</code></span>
                <span><code>            count += 1</code></span>
                <span><code></code></span>
                <span><code>            # 得到最优解</code></span>
                <span><code>        f_best, idx = self.best()</code></span>
                <span><code>        print(f"F={f_best}, x={self.x[idx]}, y={self.y[idx]}")</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>sa = SA(func)</code></span>
                <span><code>sa.run()</code></span>
            </pre>
            <div>结果如下</div>
            <div><img src="../static/Math/mathematicalModeling/11.png"></div>
            <div>退火过程可视化</div>
            <div>代码</div>
            <pre id="code_block">
                <span><code>plt.plot(sa.history['T'], sa.history['f'])</code></span>
                <span><code>plt.title('SA')</code></span>
                <span><code>plt.xlabel('T')</code></span>
                <span><code>plt.ylabel('f')</code></span>
                <span><code>plt.gca().invert_xaxis()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/12.png"></div>
        </li>
        <li>
            <div>解最小值问题</div>
            <div>解上述问题</div>
            <pre id="code_block">
                <span><code>from sko.SA import SA</code></span>
                <span><code>def demo_func(x):</code></span>
                <span><code>    x1, x2 = x</code></span>
                <span><code>    return 4 * x1 ** 2 - 2.1 * x1 ** 4 + x1 ** 6 / 3 + x1 * x2 - 4 * x2 ** 2 + 4 * x2 ** 4</code></span>
                <span><code></code></span>
                <span><code>sa = SA(func=demo_func, x0=[1, 1])</code></span>
                <span><code>x_star, y_star = sa.run()</code></span>
                <span><code>print(x_star, y_star)</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/13.png"></div>
            <div>退火过程可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>plt.plot(pd.DataFrame(sa.best_y_history).cummin(axis=0))</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/14.png"></div>
        </li>
        <li>
            <div>旅行商问题</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>from scipy import spatial</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code>num_points = 50</code></span>
                <span><code></code></span>
                <span><code>points_coordinate = np.random.rand(num_points, 2)  # 生成点坐标</code></span>
                <span><code>distance_matrix = spatial.distance.cdist(points_coordinate, points_coordinate, metric='euclidean')  # 距离矩阵</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>def cal_total_distance(routine):</code></span>
                <span><code>    """</code></span>
                <span><code>    The objective function. input routine, return total distance.</code></span>
                <span><code>    cal_total_distance(np.arange(num_points))</code></span>
                <span><code>    """</code></span>
                <span><code>    num_points, = routine.shape</code></span>
                <span><code>    return sum([distance_matrix[routine[i % num_points], routine[(i + 1) % num_points]] for i in range(num_points)])</code></span>
                <span><code></code></span>
                <span><code>from sko.SA import SA_TSP</code></span>
                <span><code></code></span>
                <span><code>sa_tsp = SA_TSP(func=cal_total_distance, x0=range(num_points),T_max=100,T_min=1,L=10*num_points)</code></span>
                <span><code></code></span>
                <span><code>best_points, best_distance = sa_tsp.run()</code></span>
                <span><code>print(best_points, best_distance)</code></span>
            </pre>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>from matplotlib.ticker import FormatStrFormatter</code></span>
                <span><code></code></span>
                <span><code>fig, ax = plt.subplots(1, 2)</code></span>
                <span><code>best_points_ = np.concatenate([best_points, [best_points[0]]])</code></span>
                <span><code>best_points_coordinate = points_coordinate[best_points_, :]</code></span>
                <span><code>ax[0].plot(sa_tsp.best_y_history)</code></span>
                <span><code>ax[0].set_xlabel("Iteration")</code></span>
                <span><code>ax[0].set_ylabel("Distance")</code></span>
                <span><code>ax[1].plot(best_points_coordinate[:, 0], best_points_coordinate[:, 1],</code></span>
                <span><code>           marker='o', markerfacecolor='b', color='c', linestyle='-')</code></span>
                <span><code>ax[1].xaxis.set_major_formatter(FormatStrFormatter('%.3f'))</code></span>
                <span><code>ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))</code></span>
                <span><code>ax[1].set_xlabel("Longitude")</code></span>
                <span><code>ax[1].set_ylabel("Latitude")</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/15.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">差分进化算法</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <ol type="i">
                <li>
                    <div>初始化参数</div>
                    <div>在差分进化算法中，有几个参数比较重要，突变参数F，交叉概率Cr，种群数Np，个体维度D；这里需要注意F，Cr的取值范围通常在（0，1），但是不意味不能取超过1，这是在大多数的情况都是取（0，1）。关于种群数和个体的关系通常是Np=5D~10D，种群数也是影响整体算法的因素之一。初始化种群之后，接下来进行初始化种群。</div>
                </li>
                <li>
                    <div>初始种群</div>
                    <div>初始化种群X通常需要结合决策空间的上界和下届，分别为xmax,xmin，具体的计算如下：</div>
                    <img src="../static/Math/mathematicalModeling/16.png">
                    <div>这样以决策空间边界的初始种群被建立，用于后期的变异，交叉。其中xmax(j)，xmin(j)表示决策空间j的上界和下届。</div>
                </li>
                <li>
                    <div>种群变异</div>
                    <div>经历了初始化种群之后，对其进行变异产生变异向量，为后期的产生子代种群建立基础。具体的变异操作如下：</div>
                    <img src="../static/Math/mathematicalModeling/17.png">
                    <div>其中g表示第g代的变异向量i个体，r1,r2,r3为常量指标。</div>
                </li>
                <li>
                    <div>种群的交叉</div>
                    <div>种群的交叉是为了产生多样性的子代向量，增强种群的多样性，使结构更加复杂，促使种群的结构化差异。具体的计算公式如下：</div>
                    <img src="../static/Math/mathematicalModeling/18.png">
                    <div>进行种群的交叉之后，为了挑选出最优子代，接下来将进行选择操作。</div>
                </li>
                <li>
                    <div>最优种群的选择</div>
                    <div>为使种群能从中挑选出最优子代，将执行贪婪选择操作。具体计算公式如下：</div>
                    <img src="../static/Math/mathematicalModeling/19.png">
                </li>
            </ol>
        </li>
        <li>
            <div>约束优化问题</div>
            <div>约束函数如下</div>
            <pre id="code_block">
                <span><code>"""</code></span>
                <span><code>min f(x1, x2, x3) = x1^2 + x2^2 + x3^2</code></span>
                <span><code>s.t.</code></span>
                <span><code>    x1*x2 >= 1</code></span>
                <span><code>    x1*x2 <= 5</code></span>
                <span><code>    x2 + x3 = 1</code></span>
                <span><code>    0 <= x1, x2, x3 <= 5</code></span>
                <span><code>"""</code></span>
            </pre>
            <div>构建约束函数</div>
            <pre id="code_block">
                <span><code>def obj_func(p):</code></span>
                <span><code>    x1, x2, x3 = p</code></span>
                <span><code>    return x1 ** 2 + x2 ** 2 + x3 ** 2</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>constraint_eq = [</code></span>
                <span><code>    lambda x: 1 - x[1] - x[2]</code></span>
                <span><code>]</code></span>
                <span><code></code></span>
                <span><code>constraint_ueq = [</code></span>
                <span><code>    lambda x: 1 - x[0] * x[1],</code></span>
                <span><code>    lambda x: x[0] * x[1] - 5</code></span>
                <span><code>]</code></span>
            </pre>
            <div>利用差分进化算法求解</div>
            <pre id="code_block">
                <span><code>from sko.DE import DE</code></span>
                <span><code></code></span>
                <span><code>de = DE(func=obj_func, n_dim=3, size_pop=50, max_iter=800, lb=[0, 0, 0], ub=[5, 5, 5],</code></span>
                <span><code>        constraint_eq=constraint_eq, constraint_ueq=constraint_ueq)</code></span>
                <span><code></code></span>
                <span><code>best_x, best_y = de.run()</code></span>
                <span><code>print('best_x:', best_x, '\n' + 'best_y:', best_y)</code></span>
            </pre>
            <div>结果如下</div>
            <img src="../static/Math/mathematicalModeling/20.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">遗传算法</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>遗传算法（Genetic Algorithm，简称GA）起源于对生物系统所进行的计算机模拟研究，是一种随机全局搜索优化方法，它模拟了自然选择和遗传中发生的复制、交叉(crossover)和变异(mutation)等现象，从任一初始种群（Population）出发，通过随机选择、交叉和变异操作，产生一群更适合环境的个体，使群体进化到搜索空间中越来越好的区域，这样一代一代不断繁衍进化，最后收敛到一群最适应环境的个体（Individual），从而求得问题的优质解。</div>
        </li>
        <li>
            <div>流程分析</div>
            <img src="../static/Math/mathematicalModeling/21.png">
        </li>
        <li>
            <div>解最小值问题</div>
            <div>定义函数</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code></code></span>
                <span><code>def schaffer(p):</code></span>
                <span><code>    """</code></span>
                <span><code>    This function has plenty of local minimum, with strong shocks</code></span>
                <span><code>    global minimum at (0,0) with value 0</code></span>
                <span><code>    """</code></span>
                <span><code>    x1, x2 = p</code></span>
                <span><code>    x = np.square(x1) + np.square(x2)</code></span>
                <span><code>    return 0.5 + (np.sin(x) - 0.5) / np.square(1 + 0.001 * x)</code></span>
            </pre>
            <div>求解</div>
            <pre id="code_block">
                <span><code>from sko.GA import GA</code></span>
                <span><code></code></span>
                <span><code>ga = GA(func=schaffer, n_dim=2, size_pop=50, max_iter=800, lb=[-1, -1], ub=[1, 1], precision=1e-7)</code></span>
                <span><code>best_x, best_y = ga.run()</code></span>
                <span><code>print('best_x:', best_x, '\n' + 'best_y:', best_y)</code></span>
            </pre>
            <div>结果如下</div>
            <img src="../static/Math/mathematicalModeling/21.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import pandas as pd</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code>Y_history = pd.DataFrame(ga.all_history_Y)</code></span>
                <span><code>fig, ax = plt.subplots(2, 1)</code></span>
                <span><code>ax[0].plot(Y_history.index, Y_history.values, '.', color='red')</code></span>
                <span><code>Y_history.min(axis=1).cummin().plot(kind='line')</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/22.png">
        </li>
        <li>
            <div>旅行商问题</div>
            <div>数据生成办法同退火算法</div>
            <div>求解</div>
            <pre id="code_block">
                <span><code>from sko.GA import GA_TSP</code></span>
                <span><code></code></span>
                <span><code>ga_tsp = GA_TSP(func=cal_total_distance, n_dim=num_points, size_pop=50, max_iter=2000, prob_mut=1)</code></span>
                <span><code>best_points, best_distance = ga_tsp.run()</code></span>
                <span><code>print(best_points,best_distance)</code></span>
            </pre>
            <div>结果如下</div>
            <img src="../static/Math/mathematicalModeling/24.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>fig, ax = plt.subplots(1, 2)</code></span>
                <span><code>best_points_ = np.concatenate([best_points, [best_points[0]]])</code></span>
                <span><code>best_points_coordinate = points_coordinate[best_points_, :]</code></span>
                <span><code>ax[0].plot(best_points_coordinate[:, 0], best_points_coordinate[:, 1], 'o-r')</code></span>
                <span><code>ax[1].plot(ga_tsp.generation_best_Y)</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/25.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">粒子群算法</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>将鸟群觅食行为和算法原理对应，如下图：</div>
            <img src="../static/Math/mathematicalModeling/26.png">
            <ol type="i">
                <li><div>PSO的基础：信息的社会共享</div></li>
                <li>
                    <div>粒子的两个属性：速度和位置（算法的两个核心要素）</div>
                    <div>速度表示粒子下一步迭代时移动的方向和距离，位置是所求解问题的一个解。</div>
                </li>
                <li>
                    <div>算法的6个重要参数</div>
                    <div>假设在D维搜索空间有N个粒子，每个粒子代表一个解，则：</div>
                    <img src="../static/Math/mathematicalModeling/27.png">
                </li>
                <li>
                    <div>速度更新公式</div>
                    <div>表述上叫速度，实际上就是粒子下一步迭代移动的距离和方向，也就是一个位置向量。</div>
                    <img src="../static/Math/mathematicalModeling/28.png">
                    <ol type="A">
                        <li>
                            <div>速度更新公式的解释</div>
                            <ol type="a">
                                <li>
                                    <div>第一项：惯性部分</div>
                                    <div>由惯性权重和粒子自身速度构成，表示粒子对先前自身运动状态的信任。</div>
                                </li>
                                <li>
                                    <div>第二项：认知部分</div>
                                    <div>表示粒子本身的思考，即粒子自己经验的部分，可理解为粒子当前位置与自身历史最优位置之间的距离和方向。</div>
                                </li>
                                <li>
                                    <div>第三项：社会部分</div>
                                    <div>表示粒子之间的信息共享与合作，即来源于群体中其他优秀粒子的经验，可理解为粒子当前位置与群体历史最优位置之间的距离和方向。</div>
                                </li>
                            </ol>
                        </li>
                        <li>
                            <div>速度更新公式的参数定义</div>
                            <img src="../static/Math/mathematicalModeling/29.png">
                        </li>
                        <li>
                            <div>速度的方向</div>
                            <div>粒子下一步迭代的移动方向 = 惯性方向 + 个体最优方向 + 群体最优方向</div>
                            <img src="../static/Math/mathematicalModeling/30.png">
                        </li>
                    </ol>
                </li>
                <li>
                    <div>位置更新公式</div>
                    <div>上一步的位置 + 下一步的速度</div>
                    <img src="../static/Math/mathematicalModeling/31.png">
                </li>
                <li>
                    <div>算法参数的详细解释</div>
                    <div><img src="../static/Math/mathematicalModeling/32.png"></div>
                    <div><img src="../static/Math/mathematicalModeling/33.png"></div>
                    <div><img src="../static/Math/mathematicalModeling/34.png"></div>
                </li>
            </ol>
        </li>
        <li>
            <div>流程分析</div>
            <img src="../static/Math/mathematicalModeling/35.png">
        </li>
        <li>
            <div>带约束的粒子群算法</div>
            <div>定义函数</div>
            <pre id="code_block">
                <span><code>def demo_func(x):</code></span>
                <span><code>    x1, x2, x3 = x</code></span>
                <span><code>    return x1 ** 2 + (x2 - 0.05) ** 2 + x3 ** 2</code></span>
            </pre>
            <div>求解</div>
            <pre id="code_block">
                <span><code>from sko.PSO import PSO</code></span>
                <span><code></code></span>
                <span><code>pso = PSO(func=demo_func, dim=3, pop=40, max_iter=150, lb=[0, -1, 0.5], ub=[1, 1, 1], w=0.8, c1=0.5, c2=0.5)</code></span>
                <span><code>pso.run()</code></span>
                <span><code>print('best_x is ', pso.gbest_x, 'best_y is', pso.gbest_y)</code></span>
            </pre>
            <div>结果如下</div>
            <img src="../static/Math/mathematicalModeling/36.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code>plt.plot(pso.gbest_y_hist)</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/37.png">
        </li>
        <li>
            <div>不带约束的粒子群算法</div>
            <div>求解</div>
            <pre id="code_block">
                <span><code>from sko.PSO import PSO</code></span>
                <span><code></code></span>
                <span><code>pso = PSO(func=demo_func, dim=3)</code></span>
                <span><code>fitness = pso.run()</code></span>
                <span><code>print('best_x is ', pso.gbest_x, 'best_y is', pso.gbest_y)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/38.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code>plt.plot(pso.gbest_y_hist)</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/39.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">蚁群算法</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>假如蚁群中所有蚂蚁的数量为m，所有城市之间的信息素用矩阵pheromone表示，最短路径为bestLength，最佳路径为bestTour。每只蚂蚁都有自己的内存，内存中用一个禁忌表（Tabu）来存储该蚂蚁已经访问过的城市，表示其在以后的搜索中将不能访问这些城市；还有用另外一个允许访问的城市表（Allowed）来存储它还可以访问的城市；另外还用一个矩阵（Delta）来存储它在一个循环（或者迭代）中给所经过的路径释放的信息素；还有另外一些数据，例如一些控制参数(α，β，ρ，Q)，该蚂蚁行走玩全程的总成本或距离（tourLength），等等。假定算法总共运行MAX_GEN次，运行时间为t。</div>
        </li>
        <li>
            <div>流程分析</div>
            <ol type="i">
                <li><div>初始化。</div></li>
                <li><div>为每只蚂蚁选择下一个节点。</div></li>
                <li><div>更新信息素矩阵。</div></li>
                <li><div>检查终止条件</div></li>
                <div>如果达到最大代数MAX_GEN，算法终止，转到第（5）步；否则，重新初始化所有的蚂蚁的Delt矩阵所有元素初始化为0，Tabu表清空，Allowed表中加入所有的城市节点。随机选择它们的起始位置（也可以人工指定）。在Tabu中加入起始节点，Allowed中去掉该起始节点，重复执行（2），（3）,(4)步。</div>
                <li><div>输出最优值</div></li>
            </ol>
        </li>
        <li>
            <div>代码实现</div>
            <pre id="code_block">
                <span><code>import random</code></span>
                <span><code>import copy</code></span>
                <span><code>import sys</code></span>
                <span><code>import tkinter  # //GUI模块</code></span>
                <span><code>import threading</code></span>
                <span><code>from functools import reduce</code></span>
                <span><code></code></span>
                <span><code># 参数</code></span>
                <span><code>"""</code></span>
                <span><code>ALPHA:信息启发因子，值越大，则蚂蚁选择之前走过的路径可能性就越大</code></span>
                <span><code>      ，值越小，则蚁群搜索范围就会减少，容易陷入局部最优</code></span>
                <span><code>BETA:Beta值越大，蚁群越就容易选择局部较短路径，这时算法收敛速度会</code></span>
                <span><code>     加快，但是随机性不高，容易得到局部的相对最优</code></span>
                <span><code>"""</code></span>
                <span><code>(ALPHA, BETA, RHO, Q) = (1.0, 2.0, 0.5, 100.0)</code></span>
                <span><code># 城市数，蚁群</code></span>
                <span><code>(city_num, ant_num) = (50, 50)</code></span>
                <span><code>distance_x = [</code></span>
                <span><code>    178, 272, 176, 171, 650, 499, 267, 703, 408, 437, 491, 74, 532,</code></span>
                <span><code>    416, 626, 42, 271, 359, 163, 508, 229, 576, 147, 560, 35, 714,</code></span>
                <span><code>    757, 517, 64, 314, 675, 690, 391, 628, 87, 240, 705, 699, 258,</code></span>
                <span><code>    428, 614, 36, 360, 482, 666, 597, 209, 201, 492, 294]</code></span>
                <span><code>distance_y = [</code></span>
                <span><code>    170, 395, 198, 151, 242, 556, 57, 401, 305, 421, 267, 105, 525,</code></span>
                <span><code>    381, 244, 330, 395, 169, 141, 380, 153, 442, 528, 329, 232, 48,</code></span>
                <span><code>    498, 265, 343, 120, 165, 50, 433, 63, 491, 275, 348, 222, 288,</code></span>
                <span><code>    490, 213, 524, 244, 114, 104, 552, 70, 425, 227, 331]</code></span>
                <span><code># 城市距离和信息素</code></span>
                <span><code>distance_graph = [[0.0 for col in range(city_num)] for raw in range(city_num)]</code></span>
                <span><code>pheromone_graph = [[1.0 for col in range(city_num)] for raw in range(city_num)]</code></span>
                <span><code></code></span>
                <span><code>class Ant(object):</code></span>
                <span><code></code></span>
                <span><code>    # 初始化</code></span>
                <span><code>    def __init__(self, ID):</code></span>
                <span><code></code></span>
                <span><code>        self.ID = ID  # ID</code></span>
                <span><code>        self.__clean_data()  # 随机初始化出生点</code></span>
                <span><code></code></span>
                <span><code>    # 初始数据</code></span>
                <span><code>    def __clean_data(self):</code></span>
                <span><code></code></span>
                <span><code>        self.path = []  # 当前蚂蚁的路径</code></span>
                <span><code>        self.total_distance = 0.0  # 当前路径的总距离</code></span>
                <span><code>        self.move_count = 0  # 移动次数</code></span>
                <span><code>        self.current_city = -1  # 当前停留的城市</code></span>
                <span><code>        self.open_table_city = [True for i in range(city_num)]  # 探索城市的状态</code></span>
                <span><code></code></span>
                <span><code>        city_index = random.randint(0, city_num - 1)  # 随机初始出生点</code></span>
                <span><code>        self.current_city = city_index</code></span>
                <span><code>        self.path.append(city_index)</code></span>
                <span><code>        self.open_table_city[city_index] = False</code></span>
                <span><code>        self.move_count = 1</code></span>
                <span><code></code></span>
                <span><code>    # 选择下一个城市</code></span>
                <span><code>    def __choice_next_city(self):</code></span>
                <span><code></code></span>
                <span><code>        next_city = -1</code></span>
                <span><code>        select_citys_prob = [0.0 for i in range(city_num)]  # 存储去下个城市的概率</code></span>
                <span><code>        total_prob = 0.0</code></span>
                <span><code></code></span>
                <span><code>        # 获取去下一个城市的概率</code></span>
                <span><code>        for i in range(city_num):</code></span>
                <span><code>            if self.open_table_city[i]:</code></span>
                <span><code>                try:</code></span>
                <span><code>                    # 计算概率：与信息素浓度成正比，与距离成反比</code></span>
                <span><code>                    select_citys_prob[i] = pow(pheromone_graph[self.current_city][i], ALPHA) * pow(</code></span>
                <span><code>                        (1.0 / distance_graph[self.current_city][i]), BETA)</code></span>
                <span><code>                    total_prob += select_citys_prob[i]</code></span>
                <span><code>                except ZeroDivisionError as e:</code></span>
                <span><code>                    print('Ant ID: {ID}, current city: {current}, target city: {target}'.format(ID=self.ID,</code></span>
                <span><code>                                                                                                current=self.current_city,</code></span>
                <span><code>                                                                                                target=i))</code></span>
                <span><code>                    sys.exit(1)</code></span>
                <span><code></code></span>
                <span><code>        # 轮盘选择城市</code></span>
                <span><code>        if total_prob > 0.0:</code></span>
                <span><code>            # 产生一个随机概率,0.0-total_prob</code></span>
                <span><code>            temp_prob = random.uniform(0.0, total_prob)</code></span>
                <span><code>            for i in range(city_num):</code></span>
                <span><code>                if self.open_table_city[i]:</code></span>
                <span><code>                    # 轮次相减</code></span>
                <span><code>                    temp_prob -= select_citys_prob[i]</code></span>
                <span><code>                    if temp_prob < 0.0:</code></span>
                <span><code>                        next_city = i</code></span>
                <span><code>                        break</code></span>
                <span><code></code></span>
                <span><code>        # 未从概率产生，顺序选择一个未访问城市</code></span>
                <span><code>        # if next_city == -1:</code></span>
                <span><code>        #     for i in range(city_num):</code></span>
                <span><code>        #         if self.open_table_city[i]:</code></span>
                <span><code>        #             next_city = i</code></span>
                <span><code>        #             break</code></span>
                <span><code></code></span>
                <span><code>        if (next_city == -1):</code></span>
                <span><code>            next_city = random.randint(0, city_num - 1)</code></span>
                <span><code>            while ((self.open_table_city[next_city]) == False):  # if==False,说明已经遍历过了</code></span>
                <span><code>                next_city = random.randint(0, city_num - 1)</code></span>
                <span><code></code></span>
                <span><code>        # 返回下一个城市序号</code></span>
                <span><code>        return next_city</code></span>
                <span><code></code></span>
                <span><code>    # 计算路径总距离</code></span>
                <span><code>    def __cal_total_distance(self):</code></span>
                <span><code></code></span>
                <span><code>        temp_distance = 0.0</code></span>
                <span><code></code></span>
                <span><code>        for i in range(1, city_num):</code></span>
                <span><code>            start, end = self.path[i], self.path[i - 1]</code></span>
                <span><code>            temp_distance += distance_graph[start][end]</code></span>
                <span><code></code></span>
                <span><code>        # 回路</code></span>
                <span><code>        end = self.path[0]</code></span>
                <span><code>        temp_distance += distance_graph[start][end]</code></span>
                <span><code>        self.total_distance = temp_distance</code></span>
                <span><code></code></span>
                <span><code>    # 移动操作</code></span>
                <span><code>    def __move(self, next_city):</code></span>
                <span><code></code></span>
                <span><code>        self.path.append(next_city)</code></span>
                <span><code>        self.open_table_city[next_city] = False</code></span>
                <span><code>        self.total_distance += distance_graph[self.current_city][next_city]</code></span>
                <span><code>        self.current_city = next_city</code></span>
                <span><code>        self.move_count += 1</code></span>
                <span><code></code></span>
                <span><code>    # 搜索路径</code></span>
                <span><code>    def search_path(self):</code></span>
                <span><code></code></span>
                <span><code>        # 初始化数据</code></span>
                <span><code>        self.__clean_data()</code></span>
                <span><code></code></span>
                <span><code>        # 搜素路径，遍历完所有城市为止</code></span>
                <span><code>        while self.move_count < city_num:</code></span>
                <span><code>            # 移动到下一个城市</code></span>
                <span><code>            next_city = self.__choice_next_city()</code></span>
                <span><code>            self.__move(next_city)</code></span>
                <span><code></code></span>
                <span><code>        # 计算路径总长度</code></span>
                <span><code>        self.__cal_total_distance()</code></span>
                <span><code></code></span>
                <span><code>class TSP(object):</code></span>
                <span><code></code></span>
                <span><code>    def __init__(self, root, width=800, height=600, n=city_num):</code></span>
                <span><code></code></span>
                <span><code>        # 创建画布</code></span>
                <span><code>        self.root = root</code></span>
                <span><code>        self.width = width</code></span>
                <span><code>        self.height = height</code></span>
                <span><code>        # 城市数目初始化为city_num</code></span>
                <span><code>        self.n = n</code></span>
                <span><code>        # tkinter.Canvas</code></span>
                <span><code>        self.canvas = tkinter.Canvas(</code></span>
                <span><code>            root,</code></span>
                <span><code>            width=self.width,</code></span>
                <span><code>            height=self.height,</code></span>
                <span><code>            bg="#EBEBEB",  # 背景白色</code></span>
                <span><code>            xscrollincrement=1,</code></span>
                <span><code>            yscrollincrement=1</code></span>
                <span><code>        )</code></span>
                <span><code>        self.canvas.pack(expand=tkinter.YES, fill=tkinter.BOTH)</code></span>
                <span><code>        self.title("TSP蚁群算法(n:初始化 e:开始搜索 s:停止搜索 q:退出程序)")</code></span>
                <span><code>        self.__r = 5</code></span>
                <span><code>        self.__lock = threading.RLock()  # 线程锁</code></span>
                <span><code></code></span>
                <span><code>        self.__bindEvents()</code></span>
                <span><code>        self.new()</code></span>
                <span><code></code></span>
                <span><code>        # 计算城市之间的距离</code></span>
                <span><code>        for i in range(city_num):</code></span>
                <span><code>            for j in range(city_num):</code></span>
                <span><code>                temp_distance = pow((distance_x[i] - distance_x[j]), 2) + pow((distance_y[i] - distance_y[j]), 2)</code></span>
                <span><code>                temp_distance = pow(temp_distance, 0.5)</code></span>
                <span><code>                distance_graph[i][j] = float(int(temp_distance + 0.5))</code></span>
                <span><code></code></span>
                <span><code>    # 按键响应程序</code></span>
                <span><code>    def __bindEvents(self):</code></span>
                <span><code></code></span>
                <span><code>        self.root.bind("q", self.quite)  # 退出程序</code></span>
                <span><code>        self.root.bind("n", self.new)  # 初始化</code></span>
                <span><code>        self.root.bind("e", self.search_path)  # 开始搜索</code></span>
                <span><code>        self.root.bind("s", self.stop)  # 停止搜索</code></span>
                <span><code></code></span>
                <span><code>    # 更改标题</code></span>
                <span><code>    def title(self, s):</code></span>
                <span><code></code></span>
                <span><code>        self.root.title(s)</code></span>
                <span><code></code></span>
                <span><code>    # 初始化</code></span>
                <span><code>    def new(self, evt=None):</code></span>
                <span><code></code></span>
                <span><code>        # 停止线程</code></span>
                <span><code>        self.__lock.acquire()</code></span>
                <span><code>        self.__running = False</code></span>
                <span><code>        self.__lock.release()</code></span>
                <span><code></code></span>
                <span><code>        self.clear()  # 清除信息</code></span>
                <span><code>        self.nodes = []  # 节点坐标</code></span>
                <span><code>        self.nodes2 = []  # 节点对象</code></span>
                <span><code></code></span>
                <span><code>        # 初始化城市节点</code></span>
                <span><code>        for i in range(len(distance_x)):</code></span>
                <span><code>            # 在画布上随机初始坐标</code></span>
                <span><code>            x = distance_x[i]</code></span>
                <span><code>            y = distance_y[i]</code></span>
                <span><code>            self.nodes.append((x, y))</code></span>
                <span><code>            # 生成节点椭圆，半径为self.__r</code></span>
                <span><code>            node = self.canvas.create_oval(x - self.__r,</code></span>
                <span><code>                                           y - self.__r, x + self.__r, y + self.__r,</code></span>
                <span><code>                                           fill="#ff0000",  # 填充红色</code></span>
                <span><code>                                           outline="#000000",  # 轮廓白色</code></span>
                <span><code>                                           tags="node",</code></span>
                <span><code>                                           )</code></span>
                <span><code>            self.nodes2.append(node)</code></span>
                <span><code>            # 显示坐标</code></span>
                <span><code>            self.canvas.create_text(x, y - 10,  # 使用create_text方法在坐标（302，77）处绘制文字</code></span>
                <span><code>                                    text='(' + str(x) + ',' + str(y) + ')',  # 所绘制文字的内容</code></span>
                <span><code>                                    fill='black'  # 所绘制文字的颜色为灰色</code></span>
                <span><code>                                    )</code></span>
                <span><code></code></span>
                <span><code>        # 顺序连接城市</code></span>
                <span><code>        # self.line(range(city_num))</code></span>
                <span><code></code></span>
                <span><code>        # 初始城市之间的距离和信息素</code></span>
                <span><code>        for i in range(city_num):</code></span>
                <span><code>            for j in range(city_num):</code></span>
                <span><code>                pheromone_graph[i][j] = 1.0</code></span>
                <span><code></code></span>
                <span><code>        self.ants = [Ant(ID) for ID in range(ant_num)]  # 初始蚁群</code></span>
                <span><code>        self.best_ant = Ant(-1)  # 初始最优解</code></span>
                <span><code>        self.best_ant.total_distance = 1 << 31  # 初始最大距离</code></span>
                <span><code>        self.iter = 1  # 初始化迭代次数</code></span>
                <span><code></code></span>
                <span><code>    # 将节点按order顺序连线</code></span>
                <span><code>    def line(self, order):</code></span>
                <span><code>        # 删除原线</code></span>
                <span><code>        self.canvas.delete("line")</code></span>
                <span><code></code></span>
                <span><code>        def line2(i1, i2):</code></span>
                <span><code>            p1, p2 = self.nodes[i1], self.nodes[i2]</code></span>
                <span><code>            self.canvas.create_line(p1, p2, fill="#000000", tags="line")</code></span>
                <span><code>            return i2</code></span>
                <span><code></code></span>
                <span><code>        # order[-1]为初始值</code></span>
                <span><code>        reduce(line2, order, order[-1])</code></span>
                <span><code></code></span>
                <span><code>    # 清除画布</code></span>
                <span><code>    def clear(self):</code></span>
                <span><code>        for item in self.canvas.find_all():</code></span>
                <span><code>            self.canvas.delete(item)</code></span>
                <span><code></code></span>
                <span><code>    # 退出程序</code></span>
                <span><code>    def quite(self, evt):</code></span>
                <span><code>        self.__lock.acquire()</code></span>
                <span><code>        self.__running = False</code></span>
                <span><code>        self.__lock.release()</code></span>
                <span><code>        self.root.destroy()</code></span>
                <span><code>        print(u"\n程序已退出...")</code></span>
                <span><code>        sys.exit()</code></span>
                <span><code></code></span>
                <span><code>    # 停止搜索</code></span>
                <span><code>    def stop(self, evt):</code></span>
                <span><code>        self.__lock.acquire()</code></span>
                <span><code>        self.__running = False</code></span>
                <span><code>        self.__lock.release()</code></span>
                <span><code></code></span>
                <span><code>    # 开始搜索</code></span>
                <span><code>    def search_path(self, evt=None):</code></span>
                <span><code></code></span>
                <span><code>        # 开启线程</code></span>
                <span><code>        self.__lock.acquire()</code></span>
                <span><code>        self.__running = True</code></span>
                <span><code>        self.__lock.release()</code></span>
                <span><code></code></span>
                <span><code>        while self.__running:</code></span>
                <span><code>            # 遍历每一只蚂蚁</code></span>
                <span><code>            for ant in self.ants:</code></span>
                <span><code>                # 搜索一条路径</code></span>
                <span><code>                ant.search_path()</code></span>
                <span><code>                # 与当前最优蚂蚁比较</code></span>
                <span><code>                if ant.total_distance < self.best_ant.total_distance:</code></span>
                <span><code>                    # 更新最优解</code></span>
                <span><code>                    self.best_ant = copy.deepcopy(ant)</code></span>
                <span><code>            # 更新信息素</code></span>
                <span><code>            self.__update_pheromone_gragh()</code></span>
                <span><code>            print(u"迭代次数：", self.iter, u"最佳路径总距离：", int(self.best_ant.total_distance))</code></span>
                <span><code>            # 连线</code></span>
                <span><code>            self.line(self.best_ant.path)</code></span>
                <span><code>            # 设置标题</code></span>
                <span><code>            self.title("TSP蚁群算法(n:随机初始 e:开始搜索 s:停止搜索 q:退出程序) 迭代次数: %d" % self.iter)</code></span>
                <span><code>            # 更新画布</code></span>
                <span><code>            self.canvas.update()</code></span>
                <span><code>            self.iter += 1</code></span>
                <span><code></code></span>
                <span><code>    # 更新信息素</code></span>
                <span><code>    def __update_pheromone_gragh(self):</code></span>
                <span><code></code></span>
                <span><code>        # 获取每只蚂蚁在其路径上留下的信息素</code></span>
                <span><code>        temp_pheromone = [[0.0 for col in range(city_num)] for raw in range(city_num)]</code></span>
                <span><code>        for ant in self.ants:</code></span>
                <span><code>            for i in range(1, city_num):</code></span>
                <span><code>                start, end = ant.path[i - 1], ant.path[i]</code></span>
                <span><code>                # 在路径上的每两个相邻城市间留下信息素，与路径总距离反比</code></span>
                <span><code>                temp_pheromone[start][end] += Q / ant.total_distance</code></span>
                <span><code>                temp_pheromone[end][start] = temp_pheromone[start][end]</code></span>
                <span><code></code></span>
                <span><code>        # 更新所有城市之间的信息素，旧信息素衰减加上新迭代信息素</code></span>
                <span><code>        for i in range(city_num):</code></span>
                <span><code>            for j in range(city_num):</code></span>
                <span><code>                pheromone_graph[i][j] = pheromone_graph[i][j] * RHO + temp_pheromone[i][j]</code></span>
                <span><code></code></span>
                <span><code>    # 主循环</code></span>
                <span><code>    def mainloop(self):</code></span>
                <span><code>        self.root.mainloop()</code></span>
                <span><code></code></span>
                <span><code>if __name__ == '__main__':</code></span>
                <span><code>    TSP(tkinter.Tk()).mainloop()</code></span>
            </pre>
        </li>
        <li>
            <div>旅行商问题</div>
            <div>数据生成办法同退火算法</div>
            <div>求解</div>
            <pre id="code_block">
                <span><code>from sko.ACA import ACA_TSP</code></span>
                <span><code></code></span>
                <span><code>aca = ACA_TSP(func=cal_total_distance, n_dim=num_points,</code></span>
                <span><code>              size_pop=50, max_iter=1000,</code></span>
                <span><code>              distance_matrix=distance_matrix)</code></span>
                <span><code></code></span>
                <span><code>best_points, best_distance = aca.run()</code></span>
                <span><code>print(best_points, best_distance)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/40.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>from matplotlib.ticker import FormatStrFormatter</code></span>
                <span><code>fig, ax = plt.subplots(1, 2)</code></span>
                <span><code>best_points_ = np.concatenate([best_points, [best_points[0]]])</code></span>
                <span><code>best_points_coordinate = points_coordinate[best_points_, :]</code></span>
                <span><code>ax[0].plot(aca.y_best_history)</code></span>
                <span><code>ax[0].set_xlabel("Iteration")</code></span>
                <span><code>ax[0].set_ylabel("Distance")</code></span>
                <span><code>ax[1].plot(best_points_coordinate[:, 0], best_points_coordinate[:, 1],</code></span>
                <span><code>           marker='o', markerfacecolor='b', color='c', linestyle='-')</code></span>
                <span><code>ax[1].xaxis.set_major_formatter(FormatStrFormatter('%.3f'))</code></span>
                <span><code>ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))</code></span>
                <span><code>ax[1].set_xlabel("Longitude")</code></span>
                <span><code>ax[1].set_ylabel("Latitude")</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/41.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">免疫优化算法</span>
    </div>
    <ol type="I">
        <li>
            <div>流程分析</div>
            <img src="../static/Math/mathematicalModeling/42.png">
        </li>
        <li>
            <div>旅行商问题</div>
            <div>数据生成办法同退火算法</div>
            <div>求解</div>
            <pre id="code_block">
                <span><code>from sko.IA import IA_TSP</code></span>
                <span><code></code></span>
                <span><code>ia_tsp = IA_TSP(func=cal_total_distance, n_dim=num_points, size_pop=500, max_iter=800, prob_mut=0.2,</code></span>
                <span><code>                T=0.7, alpha=0.95)</code></span>
                <span><code>best_points, best_distance = ia_tsp.run()</code></span>
                <span><code>print('best routine:', best_points, 'best_distance:', best_distance)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/43.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>from matplotlib.ticker import FormatStrFormatter</code></span>
                <span><code>fig, ax = plt.subplots(1, 2)</code></span>
                <span><code>best_points_ = np.concatenate([best_points, [best_points[0]]])</code></span>
                <span><code>best_points_coordinate = points_coordinate[best_points_, :]</code></span>
                <span><code>ax[0].plot(ia_tsp.all_history_Y)</code></span>
                <span><code>ax[0].set_xlabel("Iteration")</code></span>
                <span><code>ax[0].set_ylabel("Distance")</code></span>
                <span><code>ax[1].plot(best_points_coordinate[:, 0], best_points_coordinate[:, 1],</code></span>
                <span><code>           marker='o', markerfacecolor='b', color='c', linestyle='-')</code></span>
                <span><code>ax[1].xaxis.set_major_formatter(FormatStrFormatter('%.3f'))</code></span>
                <span><code>ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))</code></span>
                <span><code>ax[1].set_xlabel("Longitude")</code></span>
                <span><code>ax[1].set_ylabel("Latitude")</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/44.png">
        </li>

    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">人工鱼群算法</span>
    </div>
    <ol type="I">
        <li>
            <div>流程分析</div>
            <img src="../static/Math/mathematicalModeling/45.png">
        </li>
        <li>
            <div>最小值问题</div>
            <div>生成函数</div>
            <pre id="code_block">
                <span><code>def func(x):</code></span>
                <span><code>    x1, x2 = x</code></span>
                <span><code>    return 1 / x1 ** 2 + x1 ** 2 + 1 / x2 ** 2 + x2 ** 2</code></span>
            </pre>
            <div>求解</div>
            <pre id="code_block">
                <span><code>from sko.AFSA import AFSA</code></span>
                <span><code></code></span>
                <span><code>afsa = AFSA(func, n_dim=2, size_pop=50, max_iter=300,</code></span>
                <span><code>            max_try_num=100, step=0.5, visual=0.3,</code></span>
                <span><code>            q=0.98, delta=0.5)</code></span>
                <span><code>best_x, best_y = afsa.run()</code></span>
                <span><code>print(best_x, best_y)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/46.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">GS（Gale-Shapley）算法</span>
    </div>
    <ol type="I">
        <li>
            <div>算法原理</div>
            <div>设有ABCD四个女生，WXYZ四个男生，设法在他们之间建立一个完美匹配M，要求每位女生只能有一个男生，每位男生只能有一个女生，而且不能出现不稳定的情况.</div>
            <div>所谓不稳定的情况是指: 假设匹配中包含A-W与B-X，但是W在现在匹配的A与未匹配的B之中更喜欢B，同时B在现在匹配的X与未匹配的W之中更青睐W，所以W和B将会私下在一起，并解除关系。</div>
            <div>为了解决这个问题，有如下算法：</div>
            <ol type="i">
                <li>
                    <div>第一个男生向他所理想的第一位女生发出apply，由于女生此时尚未收到其他男生的apply，所以她选择接受</div>
                </li>
                <li>
                    <div>第二个男生向他所理想的第一位女生发出apply，假设(if)此人此时尚未收到其他男生的apply，则她选择接受；否则，若(else if)此人此时已经收到其他男生的apply，但是她更加偏好已经在一起的男生，则他选择拒绝；再或者(else)此人此时虽然收到了apply，但是她更加偏好新来的男生，则她选择毁掉之前的关系，接受这个男生</div>
                </li>
                <li>
                    <div>其他的男生将按照Step2中的样子继续执行，当条件：存在某个男生没有匹配同时还没有向所有女生发apply不满足时，算法终止</div>
                </li>
            </ol>
        </li>
        <li>
            <div>代码实现</div>
            <pre id="code_block">
                <span><code>class GS:</code></span>
                <span><code>    def __init__(self, girls=None, boys=None):</code></span>
                <span><code>        self.girls = girls</code></span>
                <span><code>        self.boys = boys</code></span>
                <span><code></code></span>
                <span><code>    @staticmethod</code></span>
                <span><code>    def _shuffle(arr, random_state=None):</code></span>
                <span><code>        from random import shuffle</code></span>
                <span><code>        if random_state is not None:</code></span>
                <span><code>            from random import seed</code></span>
                <span><code>            seed(random_state)</code></span>
                <span><code>        arr_new = arr.copy()</code></span>
                <span><code>        shuffle(arr_new)</code></span>
                <span><code>        return arr_new</code></span>
                <span><code></code></span>
                <span><code>    def random(self, n_girls, n_boys, random_state=None):</code></span>
                <span><code>        if random_state is not None:</code></span>
                <span><code>            from random import seed, randint</code></span>
                <span><code>            seed(random_state)</code></span>
                <span><code>            random_seed = [randint(0, 100) for _ in range(max(n_boys, n_girls))]</code></span>
                <span><code>        else:</code></span>
                <span><code>            random_seed = [None] * max(n_boys, n_girls)</code></span>
                <span><code>        self.girls = [self._shuffle([*range(n_boys)], random_seed[i]) for i in range(n_girls)]</code></span>
                <span><code>        self.boys = [self._shuffle([*range(n_girls)], random_seed[i]) for i in range(n_boys)]</code></span>
                <span><code></code></span>
                <span><code>    @property</code></span>
                <span><code>    def n_girls(self):</code></span>
                <span><code>        return len(self.girls)</code></span>
                <span><code></code></span>
                <span><code>    @property</code></span>
                <span><code>    def n_boys(self):</code></span>
                <span><code>        return len(self.boys)</code></span>
                <span><code></code></span>
                <span><code>    @staticmethod</code></span>
                <span><code>    def findBest(boyArr, girlChoose):</code></span>
                <span><code>        for g in girlChoose:</code></span>
                <span><code>            if g in boyArr:</code></span>
                <span><code>                return g</code></span>
                <span><code></code></span>
                <span><code>    def run(self):</code></span>
                <span><code>        if self.n_boys == self.n_girls:</code></span>
                <span><code>            container = [[] for _ in range(self.n_girls)]</code></span>
                <span><code>            for index, boy in enumerate(self.boys):</code></span>
                <span><code>                container[boy[0]].append(boy + [index, 0])</code></span>
                <span><code>            while True:</code></span>
                <span><code>                for index, cont in enumerate(container):</code></span>
                <span><code>                    if len(cont) == 0:</code></span>
                <span><code>                        continue</code></span>
                <span><code>                    if len(cont) > 1:</code></span>
                <span><code>                        boys_arr = [c[-2] for c in cont]</code></span>
                <span><code>                        boyChooseId = self.findBest(boys_arr, self.girls[index])</code></span>
                <span><code>                        for c in cont:</code></span>
                <span><code>                            if c[-2] != boyChooseId:</code></span>
                <span><code>                                c[-1] += 1</code></span>
                <span><code>                                container[c[c[-1]]].append(c)</code></span>
                <span><code>                            else:</code></span>
                <span><code>                                boyChoose = c.copy()</code></span>
                <span><code>                        container[index] = [boyChoose.copy()]</code></span>
                <span><code>                        break</code></span>
                <span><code>                else:</code></span>
                <span><code>                    break</code></span>
                <span><code>            self.boys = [cont[0][:-2] for cont in container]</code></span>
                <span><code>            ans = {value: cont[0][-2] for value, cont in enumerate(container)}</code></span>
                <span><code>            ans['girls'] = 'boys'</code></span>
                <span><code>            return ans</code></span>
                <span><code>        elif self.n_girls > self.n_boys:</code></span>
                <span><code>            container = [[] for _ in range(self.n_girls)]</code></span>
                <span><code>            for index, boy in enumerate(self.boys):</code></span>
                <span><code>                container[boy[0]].append(boy + [index, 0])</code></span>
                <span><code>            while True:</code></span>
                <span><code>                for index, cont in enumerate(container):</code></span>
                <span><code>                    if len(cont) == 0:</code></span>
                <span><code>                        continue</code></span>
                <span><code>                    if len(cont) > 1:</code></span>
                <span><code>                        boys_arr = [c[-2] for c in cont]</code></span>
                <span><code>                        boyChooseId = self.findBest(boys_arr, self.girls[index])</code></span>
                <span><code>                        for c in cont:</code></span>
                <span><code>                            if c[-2] != boyChooseId:</code></span>
                <span><code>                                c[-1] += 1</code></span>
                <span><code>                                container[c[c[-1]]].append(c)</code></span>
                <span><code>                            else:</code></span>
                <span><code>                                boyChoose = c.copy()</code></span>
                <span><code>                        container[index] = [boyChoose.copy()]</code></span>
                <span><code>                        break</code></span>
                <span><code>                else:</code></span>
                <span><code>                    break</code></span>
                <span><code>            self.boys = [cont[0][:-2] if cont else [] for cont in container]</code></span>
                <span><code>            ans = {}</code></span>
                <span><code>            for value, cont in enumerate(container):</code></span>
                <span><code>                if cont:</code></span>
                <span><code>                    ans[value] = cont[0][-2]</code></span>
                <span><code>                else:</code></span>
                <span><code>                    ans[value] = None</code></span>
                <span><code>            ans['girls'] = 'boys'</code></span>
                <span><code>            return ans</code></span>
                <span><code>        else:</code></span>
                <span><code>            container = [[] for _ in range(self.n_boys)]</code></span>
                <span><code>            for index, girl in enumerate(self.girls):</code></span>
                <span><code>                container[girl[0]].append(girl + [index, 0])</code></span>
                <span><code>            while True:</code></span>
                <span><code>                for index, cont in enumerate(container):</code></span>
                <span><code>                    if len(cont) == 0:</code></span>
                <span><code>                        continue</code></span>
                <span><code>                    if len(cont) > 1:</code></span>
                <span><code>                        girls_arr = [c[-2] for c in cont]</code></span>
                <span><code>                        girlChooseId = self.findBest(girls_arr, self.boys[index])</code></span>
                <span><code>                        for c in cont:</code></span>
                <span><code>                            if c[-2] != girlChooseId:</code></span>
                <span><code>                                c[-1] += 1</code></span>
                <span><code>                                container[c[c[-1]]].append(c)</code></span>
                <span><code>                            else:</code></span>
                <span><code>                                girlChoose = c.copy()</code></span>
                <span><code>                        container[index] = [girlChoose.copy()]</code></span>
                <span><code>                        break</code></span>
                <span><code>                else:</code></span>
                <span><code>                    break</code></span>
                <span><code>            self.girls = [cont[0][:-2] if cont else [] for cont in container]</code></span>
                <span><code>            ans = {}</code></span>
                <span><code>            for value, cont in enumerate(container):</code></span>
                <span><code>                if cont:</code></span>
                <span><code>                    ans[value] = cont[0][-2]</code></span>
                <span><code>                else:</code></span>
                <span><code>                    ans[value] = None</code></span>
                <span><code>            ans['boys'] = 'girls'</code></span>
                <span><code>            return ans</code></span>
            </pre>
            <div>生成每个男生（女生）对女生（男生）的喜欢程度排名</div>
            <pre id="code_block">
                <span><code>gs = GS()</code></span>
                <span><code>gs.random(5, 5, 42)</code></span>
                <span><code>print("boys:   " + str(gs.boys))</code></span>
                <span><code>print('girls:  ' + str(gs.girls))</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/47.png">
            <div>求解</div>
            <pre id="code_block">
                <span><code>print(gs.run())</code></span>
                <span><code>print("boys:   " + str(gs.boys))</code></span>
                <span><code>print('girls:  ' + str(gs.girls))</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/48.png">
            <div>也可以解决男女人数不相等的情况</div>
            <pre id="code_block">
                <span><code>gs = GS()</code></span>
                <span><code>gs.random(5, 6, 42)</code></span>
                <span><code>print(gs.run())</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/49.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">灰色关联分析</span>
    </div>
    <ol type="I">
        <li>
            <div>作用：</div>
            <div>灰色关联度分析对于一个系统发展变化态势提供了量化的度量，非常适合动态历程分析。</div>
        </li>
        <li>
            <div>步骤：</div>
            <ol type="i">
                <li><div>确定分析数列</div></li>
                <li>
                    <div>变量的无量纲化</div>
                    <div>1、标准化</div>
                    <div>2、归一化</div>
                </li>
                <li>
                    <div>计算关联系数</div>
                </li>
            </ol>
        </li>
        <li>
            <div>代码实现</div>
            <div>获取数据集</div>
            <pre id="code_block">
                <span><code>import pandas as pd</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>from sklearn.datasets import load_wine</code></span>
                <span><code></code></span>
                <span><code>data = load_wine().data</code></span>
                <span><code>feature = load_wine().feature_names</code></span>
                <span><code>wine = pd.DataFrame({feature[i]: data[:,i] for i in range((len(feature)))})</code></span>
            </pre>
            <div>求灰色关联度矩阵</div>
            <pre id="code_block">
                <span><code>def dimensionlessProcessing(df_values, df_columns):</code></span>
                <span><code>    from sklearn.preprocessing import StandardScaler</code></span>
                <span><code>    scaler = StandardScaler()</code></span>
                <span><code>    res = scaler.fit_transform(df_values)</code></span>
                <span><code>    return pd.DataFrame(res, columns=df_columns)</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code># 求第一列(影响因素)和其它所有列(影响因素)的灰色关联值</code></span>
                <span><code>def GRA_ONE(data, m=0):  # m为参考列</code></span>
                <span><code>    # 标准化</code></span>
                <span><code>    data = dimensionlessProcessing(data.values, data.columns)</code></span>
                <span><code>    # 参考数列</code></span>
                <span><code>    std = data.iloc[:, m]</code></span>
                <span><code>    # 比较数列</code></span>
                <span><code>    ce = data.copy()</code></span>
                <span><code></code></span>
                <span><code>    n = ce.shape[0]</code></span>
                <span><code>    m = ce.shape[1]</code></span>
                <span><code></code></span>
                <span><code>    # 与参考数列比较，相减</code></span>
                <span><code>    grap = np.zeros([n, m])</code></span>
                <span><code>    for i in range(m):</code></span>
                <span><code>        for j in range(n):</code></span>
                <span><code>            grap[j, i] = abs(ce.iloc[j, i] - std[j])</code></span>
                <span><code></code></span>
                <span><code>    # 取出矩阵中的最大值和最小值</code></span>
                <span><code>    mmax = np.amax(grap)</code></span>
                <span><code>    mmin = np.amin(grap)</code></span>
                <span><code>    ρ = 0.5  # 灰色分辨系数</code></span>
                <span><code></code></span>
                <span><code>    # 计算值</code></span>
                <span><code>    grap = pd.DataFrame(grap).applymap(lambda x: (mmin + ρ * mmax) / (x + ρ * mmax))</code></span>
                <span><code></code></span>
                <span><code>    # 求均值，得到灰色关联值</code></span>
                <span><code>    RT = grap.mean(axis=0)</code></span>
                <span><code>    return pd.Series(RT)</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code># 调用GRA_ONE，求得所有因素之间的灰色关联值</code></span>
                <span><code>def GRA(data):</code></span>
                <span><code>    list_columns = np.arange(data.shape[1])</code></span>
                <span><code>    df_local = pd.DataFrame(columns=list_columns)</code></span>
                <span><code>    for i in np.arange(data.shape[1]):</code></span>
                <span><code>        df_local[df_local.columns[i]] = GRA_ONE(data, m=i)</code></span>
                <span><code>    return df_local</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>pd.set_option('display.max_columns', None)</code></span>
                <span><code>data_gra = GRA(wine)</code></span>
                <span><code>print(data_gra)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/50.png" height="400px">
            <img src="../static/Math/mathematicalModeling/51.png" height="400px">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import seaborn as sns  # 可视化图形调用库</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>def ShowGRAHeatMap(data):</code></span>
                <span><code>    # 色彩集</code></span>
                <span><code>    colormap = plt.cm.RdBu</code></span>
                <span><code>    plt.figure(figsize=(18, 16))</code></span>
                <span><code>    plt.title('Person Correlation of Features', y=1.05, size=18)</code></span>
                <span><code>    sns.heatmap(data.astype(float), linewidths=0.1, vmax=1.0, square=True, \</code></span>
                <span><code>                cmap=colormap, linecolor='white', annot=True)</code></span>
                <span><code>    plt.show()</code></span>
                <span><code></code></span>
                <span><code></code></span>
                <span><code>ShowGRAHeatMap(data_gra)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/52.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">斯皮尔曼(Spearman correlation)相关系数分析</span>
    </div>
    <ol type="I">
        <li>
            <div>原理分析</div>
            <div>斯皮尔曼相关考察的是两者单调关系（monotonic relationship）的强度，通俗地说就是两者在变大或变小的趋势上多大程度上保持步调一致</div>
            <img src="../static/Math/mathematicalModeling/53.png">
            <div>p值检验</div>
            <div>如果p值小于0.05的话，我们可以认为存在显著性的差异，即有明显的相关性</div>
        </li>
        <li>
            <div>使用场景</div>
            <ol type="i">
                <li><div>数据展现的是非线性关系，或者不是正态分布的。</div></li>
                <li><div>至少有一方数据是序数类型（ordinal）而非数值类型</div></li>
                <li><div>数据中有明显的异常值</div></li>
            </ol>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>from sklearn.datasets import load_wine</code></span>
                <span><code></code></span>
                <span><code>data = load_wine().data</code></span>
                <span><code>feature = load_wine().feature_names</code></span>
                <span><code>wine = pd.DataFrame({feature[i]: data[:, i] for i in range((len(feature)))})</code></span>
            </pre>
            <div>计算斯皮尔曼系数矩阵</div>
            <pre id="code_block">
                <span><code>import pandas as pd</code></span>
                <span><code>import scipy.stats as stats</code></span>
                <span><code></code></span>
                <span><code>def calculate_spearman_correlation(X, Y):</code></span>
                <span><code>    return stats.spearmanr(X, Y)[0]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        spearman = calculate_spearman_correlation(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(spearman)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/54.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import seaborn as sns</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code>def ShowGRAHeatMap(data):</code></span>
                <span><code>    # 色彩集</code></span>
                <span><code>    colormap = plt.cm.RdBu</code></span>
                <span><code>    plt.figure(figsize=(18, 16))</code></span>
                <span><code>    plt.title('Person Correlation of Features', y=1.05, size=18)</code></span>
                <span><code>    sns.heatmap(data.astype(float), linewidths=0.1, vmax=1.0, square=True, \</code></span>
                <span><code>                cmap=colormap, linecolor='white', annot=True)</code></span>
                <span><code>    plt.show()</code></span>
                <span><code></code></span>
                <span><code>ShowGRAHeatMap(data)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/55.png">
            <div>计算p矩阵</div>
            <pre id="code_block">
                <span><code>def calculate_spearman_correlation_p(X, Y):</code></span>
                <span><code>    return stats.spearmanr(X, Y)[1]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        spearman = calculate_spearman_correlation_p(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(spearman)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/56.png">
            <img src="../static/Math/mathematicalModeling/57.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">皮尔逊(Pearson correlation)相关系数分析</span>
    </div>
    <ol type="I">
        <li>
            <div>原理分析</div>
            <div>皮尔逊相关系数衡量两个随机变量之间的线性关系（或者说线性关联度）</div>
            <img src="../static/Math/mathematicalModeling/58.png">
            <div>p值检验</div>
            <div>如果p值小于0.05的话，我们可以认为存在显著性的差异，即有明显的相关性</div>
        </li>
        <li>
            <div>使用场景</div>
            <ol type="i">
                <li><div>两个变量之间是线性关系，都是连续数据。</div></li>
                <li><div>两个变量的总体是正态分布，或接近正态的单峰分布。</div></li>
                <li><div>两个变量的观测值是成对的，每对观测值之间相互独立。</div></li>
            </ol>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>from sklearn.datasets import load_wine</code></span>
                <span><code></code></span>
                <span><code>data = load_wine().data</code></span>
                <span><code>feature = load_wine().feature_names</code></span>
                <span><code>wine = pd.DataFrame({feature[i]: data[:, i] for i in range((len(feature)))})</code></span>
            </pre>
            <div>计算皮尔逊系数矩阵</div>
            <pre id="code_block">
                <span><code>import pandas as pd</code></span>
                <span><code>import scipy.stats as stats</code></span>
                <span><code></code></span>
                <span><code>def calculate_pearsonr_correlation(X, Y):</code></span>
                <span><code>    return stats.pearsonr(X, Y)[0]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        pearsonr = calculate_pearsonr_correlation(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(pearsonr)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/59.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import seaborn as sns</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code>def ShowGRAHeatMap(data):</code></span>
                <span><code>    # 色彩集</code></span>
                <span><code>    colormap = plt.cm.RdBu</code></span>
                <span><code>    plt.figure(figsize=(18, 16))</code></span>
                <span><code>    plt.title('Person Correlation of Features', y=1.05, size=18)</code></span>
                <span><code>    sns.heatmap(data.astype(float), linewidths=0.1, vmax=1.0, square=True, \</code></span>
                <span><code>                cmap=colormap, linecolor='white', annot=True)</code></span>
                <span><code>    plt.show()</code></span>
                <span><code></code></span>
                <span><code>ShowGRAHeatMap(data)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/60.png">
            <div>计算p矩阵</div>
            <pre id="code_block">
                <span><code>def calculate_pearsonr_correlation_p(X, Y):</code></span>
                <span><code>    return stats.pearsonr(X, Y)[1]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        pearsonr = calculate_pearsonr_correlation_p(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(pearsonr)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/61.png">
            <img src="../static/Math/mathematicalModeling/62.png">
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">肯德尔(Kendall)相关系数分析</span>
    </div>
    <ol type="I">
        <li>
            <div>原理分析</div>
            <div>肯德尔相关系数基于样本数据对之间的关系来进行相关系数的强弱的分析，数据对可以分为一致对(Concordant)和分歧对(Discordant)。</div>
            <div>肯德尔系数有两个计算公式，一个称为Tau-c，另一个称为Tau-b。两者的区别是Tau-b可以处理有相同值的情况，即并列排位(tied ranks)。</div>
            <div><img src="../static/Math/mathematicalModeling/63.png"></div>
            <div><img src="../static/Math/mathematicalModeling/64.png"></div>
            <div>p值检验</div>
            <div>如果p值小于0.05的话，我们可以认为存在显著性的差异，即有明显的相关性</div>
        </li>
        <li>
            <div>使用场景</div>
            <div>当数据样本比较小，而且存在并列排位（tied ranks，比如说小明的历史成绩和英语成绩排名都是第8名）时，肯德尔相关系数是比斯皮尔曼相关系数更合适的一个相关性衡量指标。</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>from sklearn.datasets import load_wine</code></span>
                <span><code></code></span>
                <span><code>data = load_wine().data</code></span>
                <span><code>feature = load_wine().feature_names</code></span>
                <span><code>wine = pd.DataFrame({feature[i]: data[:, i] for i in range((len(feature)))})</code></span>
            </pre>
            <div>计算肯德尔c系数矩阵</div>
            <pre id="code_block">
                <span><code>import pandas as pd</code></span>
                <span><code>import scipy.stats as stats</code></span>
                <span><code></code></span>
                <span><code>def calculate_kendalltau_correlation_c(X, Y):</code></span>
                <span><code>    return stats.kendalltau(X, Y,variant='c')[0]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        kendalltau_c = calculate_kendalltau_correlation_c(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(kendalltau_c)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/65.png">
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import seaborn as sns</code></span>
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code></code></span>
                <span><code>def ShowGRAHeatMap(data):</code></span>
                <span><code>    # 色彩集</code></span>
                <span><code>    colormap = plt.cm.RdBu</code></span>
                <span><code>    plt.figure(figsize=(18, 16))</code></span>
                <span><code>    plt.title('Person Correlation of Features', y=1.05, size=18)</code></span>
                <span><code>    sns.heatmap(data.astype(float), linewidths=0.1, vmax=1.0, square=True, \</code></span>
                <span><code>                cmap=colormap, linecolor='white', annot=True)</code></span>
                <span><code>    plt.show()</code></span>
                <span><code></code></span>
                <span><code>ShowGRAHeatMap(data)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/66.png">
            <div>计算p矩阵</div>
            <pre id="code_block">
                <span><code>def calculate_kendalltau_correlation_cp(X, Y):</code></span>
                <span><code>    return stats.kendalltau(X, Y,variant='c')[1]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        kendalltau_cp = calculate_kendalltau_correlation_cp(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(kendalltau_cp)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/67.png">
            <img src="../static/Math/mathematicalModeling/68.png">
            <div>计算肯德尔b系数矩阵</div>
            <pre id="code_block">
                <span><code>def calculate_kendalltau_correlation_b(X, Y):</code></span>
                <span><code>    return stats.kendalltau(X, Y,variant='b')[0]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        kendalltau_b = calculate_kendalltau_correlation_b(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(kendalltau_b)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/69.png">
            <img src="../static/Math/mathematicalModeling/70.png">
        </li>
        <div>计算p矩阵</div>
            <pre id="code_block">
                <span><code>def calculate_kendalltau_correlation_bp(X, Y):</code></span>
                <span><code>    return stats.kendalltau(X, Y,variant='b')[1]</code></span>
                <span><code></code></span>
                <span><code>arr = []</code></span>
                <span><code>for a in feature:</code></span>
                <span><code>    arr2 = []</code></span>
                <span><code>    for b in feature:</code></span>
                <span><code>        kendalltau_bp = calculate_kendalltau_correlation_bp(wine[a], wine[b])</code></span>
                <span><code>        arr2.append(kendalltau_bp)</code></span>
                <span><code>    arr.append(arr2)</code></span>
                <span><code>data = pd.DataFrame(arr)</code></span>
            </pre>
            <img src="../static/Math/mathematicalModeling/71.png">
            <img src="../static/Math/mathematicalModeling/72.png">
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">灰度预测</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <ol type="i">
                <li>
                    <div>生成累加数据</div>
                    <div><img src="../static/Math/mathematicalModeling/73.png"></div>
                </li>
                <li>
                    <div>累加后的数据表达式</div>
                    <div><img src="../static/Math/mathematicalModeling/74.png"></div>
                </li>
                <li>
                    <div>求解2.2的未知参数</div>
                    <div><img src="../static/Math/mathematicalModeling/75.png"></div>
                </li>

            </ol>
        </li>
        <li>
            <div>使用场景</div>
            <div>数据量小的中短期的预测，似于指数增长的预测</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>现有1997—2002年各项指标相关统计数据如下表：</div>
            <table border="4">
                <tr>
                    <th>年份</th>
                    <th>第一产业GDP</th>
                    <th>居民消费价格指数</th>
                    <th>第三产业GDP</th>
                </tr>
                <tr>
                    <td>1997</td>
                    <td>72.03</td>
                    <td>241.2</td>
                    <td>1592.74</td>
                </tr>
                <tr>
                    <td>1998</td>
                    <td>73.84</td>
                    <td>241.2</td>
                    <td>1855.36</td>
                </tr>
                <tr>
                    <td>1999</td>
                    <td>74.49</td>
                    <td>244.8</td>
                    <td>2129.6</td>
                </tr>
                <tr>
                    <td>2000</td>
                    <td>76.68</td>
                    <td>250.9</td>
                    <td>2486.86</td>
                </tr>
                <tr>
                    <td>2001</td>
                    <td>78.0</td>
                    <td>250.9</td>
                    <td>2728.94</td>
                </tr>
                <tr>
                    <td>2002</td>
                    <td>79.68</td>
                    <td>252.2</td>
                    <td>3038.9</td>
                </tr>
            </table>
            <div>已知实际的预测数据如下：</div>
            <table border="4">
                <tr>
                    <th>年份</th>
                    <th>第一产业GDP</th>
                    <th>居民消费价格指数</th>
                    <th>第三产业GDP</th>
                </tr>
                <tr>
                    <td>2003</td>
                    <td>81.21</td>
                    <td>256.5</td>
                    <td>3458.05</td>
                </tr>
                <tr>
                    <td>2004</td>
                    <td>82.84</td>
                    <td>259.4</td>
                    <td>3900.27</td>
                </tr>
                <tr>
                    <td>2005</td>
                    <td>84.5</td>
                    <td>262.4</td>
                    <td>4399.06</td>
                </tr>
                <tr>
                    <td>2006</td>
                    <td>86.19</td>
                    <td>265.3</td>
                    <td>4961.62</td>
                </tr>
                <tr>
                    <td>2007</td>
                    <td>87.92</td>
                    <td>268.3</td>
                    <td>5596.13</td>
                </tr>
                <tr>
                    <td>2008</td>
                    <td>89.69</td>
                    <td>271.4</td>
                    <td>6311.79</td>
                </tr>
                <tr>
                    <td>2009</td>
                    <td>91.49</td>
                    <td>274.5</td>
                    <td>7118.96</td>
                </tr>
            </table>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code></code></span>
                <span><code># 原数据</code></span>
                <span><code>data = np.array([[72.03, 241.2, 1592.74], [73.84, 241.2, 1855.36], [74.49, 244.8, 2129.60], [76.68, 250.9, 2486.86],</code></span>
                <span><code>                 [78.00, 250.9, 2728.94], [79.68, 252.2, 3038.90]])</code></span>
                <span><code># 要预测数据的真实值</code></span>
                <span><code>data_T = np.array([[81.21, 256.5, 3458.05], [82.84, 259.4, 3900.27], [84.5, 262.4, 4399.06], [86.19, 265.3, 4961.62],</code></span>
                <span><code>                   [87.92, 268.3, 5596.1], [89.69, 271.4, 6311.79], [91.49, 274.5, 7118.96]])</code></span>
            </pre>
            <div>灰度预测</div>
            <pre id="code_block">
                <span><code># 累加数据</code></span>
                <span><code>data1 = np.cumsum(data.T, 1)</code></span>
                <span><code></code></span>
                <span><code>[m, n] = data1.shape  # 得到行数和列数</code></span>
                <span><code># 对这三列分别进行预测</code></span>
                <span><code>X = [i for i in range(1997, 2003)]  # 已知年份数据</code></span>
                <span><code>X = np.array(X)</code></span>
                <span><code>X_p = [i for i in range(2003, 2010)]  # 预测年份数据</code></span>
                <span><code>X_p = np.array(X_p)</code></span>
                <span><code>X_sta = X[0] - 1  # 最开始参考数据</code></span>
                <span><code># 求解未知数</code></span>
                <span><code>for j in range(3):</code></span>
                <span><code>    B = np.zeros((n - 1, 2))</code></span>
                <span><code>    for i in range(n - 1):</code></span>
                <span><code>        B[i, 0] = -1 / 2 * (data1[j, i] + data1[j, i + 1])</code></span>
                <span><code>        B[i, 1] = 1</code></span>
                <span><code>    Y = data.T[j, 1:7]</code></span>
                <span><code>    a_u = np.dot(np.dot(np.linalg.inv(np.dot(B.T, B)), B.T), Y.T)</code></span>
                <span><code>    #     print(a_u)</code></span>
                <span><code>    # 进行数据预测</code></span>
                <span><code>    a = a_u[0]</code></span>
                <span><code>    u = a_u[1]</code></span>
                <span><code>    print(np.array([a,u]))</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/76.png"></div>
            <div>误差分析及可视化</div>
            <div>由于可视化及误差代码嵌套在计算代码中，故附上完整代码</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import matplotlib as mpl</code></span>
                <span><code></code></span>
                <span><code>mpl.rcParams['font.sans-serif'] = ['SimHei']</code></span>
                <span><code>mpl.rcParams['axes.unicode_minus'] = False</code></span>
                <span><code></code></span>
                <span><code>import numpy as np</code></span>
                <span><code></code></span>
                <span><code># 原数据</code></span>
                <span><code>data = np.array([[72.03, 241.2, 1592.74], [73.84, 241.2, 1855.36], [74.49, 244.8, 2129.60], [76.68, 250.9, 2486.86],</code></span>
                <span><code>                 [78.00, 250.9, 2728.94], [79.68, 252.2, 3038.90]])</code></span>
                <span><code># 要预测数据的真实值</code></span>
                <span><code>data_T = np.array([[81.21, 256.5, 3458.05], [82.84, 259.4, 3900.27], [84.5, 262.4, 4399.06], [86.19, 265.3, 4961.62],</code></span>
                <span><code>                   [87.92, 268.3, 5596.1], [89.69, 271.4, 6311.79], [91.49, 274.5, 7118.96]])</code></span>
                <span><code></code></span>
                <span><code># 累加数据</code></span>
                <span><code>data1 = np.cumsum(data.T, 1)</code></span>
                <span><code></code></span>
                <span><code>[m, n] = data1.shape  # 得到行数和列数</code></span>
                <span><code># 对这三列分别进行预测</code></span>
                <span><code>X = [i for i in range(1997, 2003)]  # 已知年份数据</code></span>
                <span><code>X = np.array(X)</code></span>
                <span><code>X_p = [i for i in range(2003, 2010)]  # 预测年份数据</code></span>
                <span><code>X_p = np.array(X_p)</code></span>
                <span><code>X_sta = X[0] - 1  # 最开始参考数据</code></span>
                <span><code># 求解未知数</code></span>
                <span><code>fig, ax = plt.subplots(2, 2)</code></span>
                <span><code>fig.tight_layout(h_pad=2)</code></span>
                <span><code>plt.subplots_adjust(top=0.9)</code></span>
                <span><code>for j in range(3):</code></span>
                <span><code>    B = np.zeros((n - 1, 2))</code></span>
                <span><code>    for i in range(n - 1):</code></span>
                <span><code>        B[i, 0] = -1 / 2 * (data1[j, i] + data1[j, i + 1])</code></span>
                <span><code>        B[i, 1] = 1</code></span>
                <span><code>    Y = data.T[j, 1:7]</code></span>
                <span><code>    a_u = np.dot(np.dot(np.linalg.inv(np.dot(B.T, B)), B.T), Y.T)</code></span>
                <span><code>    #     print(a_u)</code></span>
                <span><code>    # 进行数据预测</code></span>
                <span><code>    a = a_u[0]</code></span>
                <span><code>    u = a_u[1]</code></span>
                <span><code>    # print(np.array([a,u]))</code></span>
                <span><code>    T = [i for i in range(1997, 2010)]</code></span>
                <span><code>    T = np.array(T)</code></span>
                <span><code>    data_p = (data1[0, j] - u / a) * np.exp(-a * (T - X_sta - 1)) + u / a  # 累加数据</code></span>
                <span><code>    #     print(data_p)</code></span>
                <span><code>    data_p1 = data_p</code></span>
                <span><code>    data_p1[1:len(data_p)] = data_p1[1:len(data_p)] - data_p1[0:len(data_p) - 1]</code></span>
                <span><code>    #     print(data_p1)</code></span>
                <span><code>    title_str = ['第一产业GDP预测', '居民消费价格指数预测', '第三产业GDP预测']</code></span>
                <span><code>    plt.subplot(221 + j)</code></span>
                <span><code>    data_n = data_p1</code></span>
                <span><code>    plt.scatter(range(1997, 2003), data[:, j])</code></span>
                <span><code>    plt.plot(range(1997, 2003), data_n[X - X_sta])</code></span>
                <span><code>    plt.scatter(range(2003, 2010), data_T[:, j])</code></span>
                <span><code>    plt.plot(range(2003, 2010), data_n[X_p - X_sta - 1])</code></span>
                <span><code>    plt.legend(['实际原数据', '拟合数据', '预测参考数据', '预测数据'])</code></span>
                <span><code>    y_n = data_n[X_p - X_sta - 1].T</code></span>
                <span><code>    y = data_T[:, j]</code></span>
                <span><code>    wucha = sum(abs(y_n - y) / y) / len(y)</code></span>
                <span><code>    titlestr1 = title_str[j]</code></span>
                <span><code>    print(title_str[j], '预测相对误差：', wucha)</code></span>
                <span><code>    plt.title(titlestr1)</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/77.png"></div>
            <div><img src="../static/Math/mathematicalModeling/78.png"></div>
        </li>

    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">贝叶斯优化</span>
    </div>
    <ol type="I">
        <li>
            <div>作用：</div>
            <div>机器学习中调参</div>
        </li>
        <li>
            <div>优点：</div>
            <ul type="disc">
                <li>贝叶斯调参采用高斯过程，考虑之前的参数信息，不断地更新先验；网格搜索未考虑之前的参数信息</li>
                <li>贝叶斯调参迭代次数少，速度快；网格搜索速度慢,参数多时易导致维度爆炸</li>
                <li>贝叶斯调参针对非凸问题依然稳健；网格搜索针对非凸问题易得到局部优最</li>
            </ul>
        </li>
        <li>
            <div>注意</div>
            <div>目标函数趋于最大值</div>
        </li>
        <li>
            <div>代码实现</div>
            <ol type="i">
                <li>
                    <div>生成数据</div>
                    <pre id="code_block">
                        <span><code>from sklearn.datasets import make_classification</code></span>
                        <span><code>from sklearn.ensemble import RandomForestClassifier</code></span>
                        <span><code>from sklearn.model_selection import cross_val_score</code></span>
                        <span><code>from bayes_opt import BayesianOptimization</code></span>
                        <span><code></code></span>
                        <span><code># 产生随机分类数据集，10个特征， 2个类别</code></span>
                        <span><code>x, y = make_classification(n_samples=1000, n_features=10, n_classes=2)</code></span>
                    </pre>
                </li>
                <li>
                    <div>无参调用</div>
                    <pre id="code_block">
                        <span><code>rf = RandomForestClassifier()</code></span>
                        <span><code>print(cross_val_score(rf, x, y, cv=10).mean())</code></span>
                    </pre>
                    <div>无参时结果：0.941</div>
                </li>
                <li>
                    <div>贝叶斯调参</div>
                    <pre id="code_block">
                        <span><code>def rf_cv(n_estimators, min_samples_split, max_features, max_depth):</code></span>
                        <span><code>    val = cross_val_score(</code></span>
                        <span><code>        RandomForestClassifier(n_estimators=int(n_estimators),</code></span>
                        <span><code>                               min_samples_split=int(min_samples_split),</code></span>
                        <span><code>                               max_features=min(max_features, 0.999),  # float</code></span>
                        <span><code>                               max_depth=int(max_depth),</code></span>
                        <span><code>                               random_state=2</code></span>
                        <span><code>                               ),</code></span>
                        <span><code>        x, y, cv=10</code></span>
                        <span><code>    ).mean()</code></span>
                        <span><code>    return val</code></span>
                        <span><code></code></span>
                        <span><code></code></span>
                        <span><code>rf_bo = BayesianOptimization(</code></span>
                        <span><code>    rf_cv,</code></span>
                        <span><code>    {'n_estimators': (10, 250),</code></span>
                        <span><code>     'min_samples_split': (2, 25),</code></span>
                        <span><code>     'max_features': (0.1, 0.999),</code></span>
                        <span><code>     'max_depth': (5, 15)}</code></span>
                        <span><code>)</code></span>
                        <span><code>rf_bo.maximize()</code></span>
                        <span><code>print(rf_bo.max)</code></span>
                    </pre>
                    <div>过程如下：</div>
                    <div><img src="../static/Math/mathematicalModeling/79.png"></div>
                    <div>结果如下：</div>
                    <div><img src="../static/Math/mathematicalModeling/80.png"></div>
                </li>
            </ol>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">基于TPE的贝叶斯优化</span>
    </div>
    <ol type="I">
        <li>
            <div>作用：</div>
            <div>机器学习中调参</div>
        </li>
        <li>
            <div>优点：</div>
            <ul type="disc">
                <li>支持各类提效工具</li>
                <li>进度条清晰，展示美观，较少怪异警告或报错</li>
                <li>可推广/拓展至深度学习领域</li>
            </ul>
        </li>
        <li>
            <div>注意</div>
            <div>目标函数趋于最小值</div>
            <div><span>函数参数可见</span><a href="https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions">github</a></div>
        </li>
        <li>
            <div>代码实现</div>
            <ol type="i">
                <li>
                    <div>导包</div>
                    <pre id="code_block">
                        <span><code>from sklearn.datasets import make_classification</code></span>
                        <span><code>from sklearn.ensemble import RandomForestClassifier</code></span>
                        <span><code>from sklearn.model_selection import cross_val_score</code></span>
                        <span><code>from hyperopt import tpe, hp, fmin, STATUS_OK, Trials</code></span>
                    </pre>
                </li>
                <li>
                    <div>生成数据</div>
                    <pre id="code_block">
                        <span><code># 产生随机分类数据集，10个特征， 2个类别</code></span>
                        <span><code>x, y = make_classification(n_samples=1000, n_features=10, n_classes=2)</code></span>
                    </pre>
                </li>
                <li>
                    <div>无参调用</div>
                    <pre id="code_block">
                        <span><code>print(cross_val_score(rf, x, y, cv=10).mean())</code></span>
                    </pre>
                    <div>无参时结果：0.9690000000000001</div>
                </li>
                <li>
                    <div>基于TPE的贝叶斯调参</div>
                    <pre id="code_block">
                        <span><code>def hyperparameter_tuning(params):</code></span>
                        <span><code>    clf = RandomForestClassifier(**params, n_jobs=-1)</code></span>
                        <span><code>    score = cross_val_score(clf, x, y, cv=5).mean()</code></span>
                        <span><code>    return {"loss": -score, "status": STATUS_OK}</code></span>
                        <span><code></code></span>
                        <span><code>space = {</code></span>
                        <span><code>    "n_estimators": hp.choice("n_estimators", [*range(10,250,10)]),</code></span>
                        <span><code>    "min_samples_split": hp.randint("min_samples_split",23)+2,</code></span>
                        <span><code>    "max_features": hp.uniform("max_features",0.1,0.999),</code></span>
                        <span><code>    'max_depth':hp.randint('max_depth',5)+10</code></span>
                        <span><code>}</code></span>
                        <span><code></code></span>
                        <span><code># 初始化Trial 对象</code></span>
                        <span><code>trials = Trials()</code></span>
                        <span><code></code></span>
                        <span><code>best = fmin(</code></span>
                        <span><code>    fn=hyperparameter_tuning,</code></span>
                        <span><code>    space=space,</code></span>
                        <span><code>    algo=tpe.suggest,</code></span>
                        <span><code>    max_evals=100,</code></span>
                        <span><code>    trials=trials</code></span>
                        <span><code>)</code></span>
                        <span><code></code></span>
                        <span><code>print("Best: {}".format(best))</code></span>
                    </pre>
                    <div>结果如下：</div>
                    <div>100%|██████████| 100/100 [01:02<00:00,  1.60it/s, best loss: -0.9789999999999999]</div>
                    <div>Best: {'max_depth': 3, 'max_features': 0.8242048339136989, 'min_samples_split': 0, 'n_estimators': 15}</div>
                    <div>使用trials对象分析结果</div>
                    <ul type="disc">
                        <li>
                            <div>trials.results</div>
                            <div>这显示搜索期间“objective”返回的词典列表。</div>
                        </li>
                        <li>
                            <div>trials.losses()</div>
                            <div>这显示了一个损失列表</div>
                        </li>
                        <li>
                            <div>trials.statuses()</div>
                            <div>这将显示状态字符串的列表。</div>
                        </li>
                    </ul>
                </li>
            </ol>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">基于optuna库贝叶斯优化</span>
    </div>
    <ol type="I">
        <li>
            <div>作用：</div>
            <div>机器学习中调参</div>
        </li>
        <li>
            <div>优点：</div>
            <ul type="disc">
                <li>代码最简洁，同时具备一定的灵活性</li>
                <li>可推广/拓展至深度学习领域</li>
            </ul>
        </li>
        <li>
            <div>注意</div>
            <div><span>基础代码</span><a href="https://tigeraus.gitee.io/doc-optuna-chinese-build/">官方文档</a></div>
            <div><span>绘图</span><a href="https://optuna.readthedocs.io/zh_CN/latest/tutorial/10_key_features/005_visualization.html">官方文档</a></div>
        </li>
        <li>
            <div>代码实现</div>
            <ol type="i">
                <li>
                    <div>导包</div>
                    <pre id="code_block">
                        <span><code>import optuna</code></span>
                        <span><code>from sklearn.datasets import make_classification</code></span>
                        <span><code>from sklearn.ensemble import RandomForestClassifier</code></span>
                        <span><code>from sklearn.model_selection import cross_val_score</code></span>
                    </pre>
                </li>
                <li>
                    <div>生成数据</div>
                    <pre id="code_block">
                        <span><code># 产生随机分类数据集，10个特征， 2个类别</code></span>
                        <span><code>x, y = make_classification(n_samples=1000, n_features=10, n_classes=2)</code></span>
                    </pre>
                </li>
                <li>
                    <div>无参调用</div>
                    <pre id="code_block">
                        <span><code>print(cross_val_score(rf, x, y, cv=10).mean())</code></span>
                    </pre>
                    <div>无参时结果：0.915</div>
                </li>
                <li>
                    <div>基于optuna库的贝叶斯调参</div>
                    <pre id="code_block">
                        <span><code>def objective(trial):</code></span>
                        <span><code>    n_estimators = trial.suggest_int('n_estimators', 10, 250, 10)</code></span>
                        <span><code>    min_samples_split = trial.suggest_int('min_samples_split', 2, 25, 1)</code></span>
                        <span><code>    max_features = trial.suggest_float('max_features', 0.1, 0.999)</code></span>
                        <span><code>    max_depth = trial.suggest_int('max_depth', 10, 15)</code></span>
                        <span><code></code></span>
                        <span><code>    model = RandomForestClassifier(n_estimators=n_estimators</code></span>
                        <span><code>                                   , min_samples_split=min_samples_split</code></span>
                        <span><code>                                   , max_features=max_features</code></span>
                        <span><code>                                   , max_depth=max_depth</code></span>
                        <span><code>                                   , n_jobs=-1)</code></span>
                        <span><code>    score = cross_val_score(model, x, y, cv=5).mean()</code></span>
                        <span><code>    return score</code></span>
                        <span><code></code></span>
                        <span><code></code></span>
                        <span><code>def optimizer_optuna(n_trials, algo):</code></span>
                        <span><code>    if algo == 'TPE':</code></span>
                        <span><code>        algo = optuna.samplers.TPESampler(n_startup_trials=10, n_ei_candidates=24)</code></span>
                        <span><code>    elif algo == 'GP':</code></span>
                        <span><code>        from optuna.integration import SkoptSampler</code></span>
                        <span><code>        import skopt</code></span>
                        <span><code>        algo = SkoptSampler(skopt_kwargs={'base_estimator': 'GP'</code></span>
                        <span><code>            , 'n_initial_points': 10</code></span>
                        <span><code>            , 'acq_func': 'EI'</code></span>
                        <span><code>                                          }</code></span>
                        <span><code>                            )</code></span>
                        <span><code></code></span>
                        <span><code>    study = optuna.create_study(sampler=algo  # 定义样本抽样的算法</code></span>
                        <span><code>                                , direction='maximize'  # 定义目标函数优化方向是最大值，还是最小值</code></span>
                        <span><code>                                )</code></span>
                        <span><code></code></span>
                        <span><code>    study.optimize(objective  # 目标函数</code></span>
                        <span><code>                   , n_trials=n_trials  # 设定最大迭代次数（包括最初观测值）</code></span>
                        <span><code>                   , show_progress_bar=True  # 要不要展示进度条</code></span>
                        <span><code>                   )</code></span>
                        <span><code>    print('best parmas:', study.best_trial.params,</code></span>
                        <span><code>          '\n', 'best score:', study.best_trial.values)</code></span>
                        <span><code></code></span>
                        <span><code>    return study.best_trial.params, study.best_trial.values</code></span>
                        <span><code></code></span>
                        <span><code># 执行流程</code></span>
                        <span><code>import warnings</code></span>
                        <span><code>warnings.filterwarnings('ignore',message='The objective has been evaluated at this point before.')</code></span>
                        <span><code></code></span>
                        <span><code>best_params,best_score=optimizer_optuna(10,'GP') # 小迭代次数代码测试</code></span>
                        <span><code></code></span>
                        <span><code>optuna.logging.set_verbosity(optuna.logging.ERROR) # 关闭打印迭代过程</code></span>
                        <span><code>best_params,best_score=optimizer_optuna(300,'GP')</code></span>
                    </pre>
                    <div>结果如下：</div>
                    <ul type="disc">
                        <li>
                            <div>小迭代次数结果：</div>
                            <div><img src="../static/Math/mathematicalModeling/81.png"></div>
                            <div>best parmas: {'n_estimators': 180, 'min_samples_split': 9, 'max_features': 0.6381708223147099, 'max_depth': 11} </div>
                            <div>best score: [0.9179999999999999]</div>
                        </li>
                        <li>
                            <div>大迭代次数结果：</div>
                            <div>Best trial: 42. Best value: 0.92: 100%|██████████| 300/300 [09:58<00:00,  2.00s/it]</div>
                            <div>best parmas: {'n_estimators': 110, 'min_samples_split': 2, 'max_features': 0.3405523360038925, 'max_depth': 15}</div>
                            <div>best score: [0.9199999999999999]</div>
                        </li>
                    </ul>
                    <div>数据保存</div>
                    <pre id="code_block">
                        <span><code>study_name = 'example-study'  # 不同的 study 不能使用相同的名字。因为当存储在同一个数据库中时，这是区分不同 study 的标识符.</code></span>
                        <span><code>study = optuna.create_study(study_name=study_name, storage='sqlite:///example.db')</code></span>
                        <span><code>study.optimize(objective, n_trials=300)</code></span>
                    </pre>
                    <div>数据读取</div>
                    <pre id="code_block">
                        <span><code>study = optuna.create_study(study_name='example-study', storage='sqlite:///example.db', load_if_exists=True)</code></span>
                    </pre>
                    <div>转换为dataframe</div>
                    <pre id="code_block">
                        <span><code>df = study.trials_dataframe(attrs=('number', 'value', 'params', 'state'))</code></span>
                    </pre>
                    <div>可视化</div>
                    <div>通用代码</div>
                    <pre id="code_block">
                        <span><code>import plotly</code></span>
                        <span><code>graph_cout = optuna.visualization.接口(study,param=['',''])(也可以不要param)</code></span>
                        <span><code>plotly.offline.plot(graph_cout)</code></span>
                    </pre>
                    <ul type="disc">
                        <li>
                            <div>plot_contour</div>
                            <div><img src="../static/Math/mathematicalModeling/82.png"></div>
                        </li>
                        <li>
                            <div>plot_optimization_history</div>
                            <div><img src="../static/Math/mathematicalModeling/83.png"></div>
                        </li>
                        <li>
                            <div>plot_parallel_coordinate</div>
                            <div><img src="../static/Math/mathematicalModeling/84.png"></div>
                        </li>
                        <li>
                            <div>plot_intermediate_values</div>
                        </li>
                        <li>
                            <div>plot_slice</div>
                            <div><img src="../static/Math/mathematicalModeling/85.png"></div>
                        </li>
                        <li>
                            <div>plot_param_importances</div>
                            <div><img src="../static/Math/mathematicalModeling/86.png"></div>
                        </li>
                        <li>
                            <div>plot_edf</div>
                            <div><img src="../static/Math/mathematicalModeling/87.png"></div>
                        </li>
                    </ul>
                </li>
            </ol>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">TOPSIS综合评价方法</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <ol type="i">
                <li>
                    <div>数据处理</div>
                    <ul type="disc">
                        <li>
                            <div>对于极小型指标的正向化处理</div>
                            <div><img src="../static/Math/mathematicalModeling/88.png"></div>
                        </li>
                        <li>
                            <div>对于中间型指标的正向化处理</div>
                            <div>我们可以取M=max{|x-middle|}</div>
                            <div><img src="../static/Math/mathematicalModeling/89.png"></div>
                        </li>
                        <li>
                            <div>对于区间型指标的正向化处理</div>
                            <div>如果其最佳区间是[a,b]，我们取M=max{a-min{x},max{x}-b}</div>
                            <div><img src="../static/Math/mathematicalModeling/90.png"></div>
                        </li>
                    </ul>
                </li>
                <li>
                    <div>数据标准化处理</div>
                    <div><img src="../static/Math/mathematicalModeling/91.png"></div>
                </li>
                <li>
                    <div>最优解与最劣解计算</div>
                    <div><img src="../static/Math/mathematicalModeling/92.png"></div>
                </li>
                <li>
                    <div>TOPSIS评分计算</div>
                    <div>计算它与最优解的距离和与最劣解的距离，求综合距离：</div>
                    <div><img src="../static/Math/mathematicalModeling/93.png"></div>
                </li>
            </ol>
        </li>
        <li>
            <div>代码实现</div>
            <pre id="code_block">
                <span><code>class TOPSIS:</code></span>
                <span><code>    def __init__(self, dataframe):</code></span>
                <span><code>        self.file = dataframe</code></span>
                <span><code>        self.finished = []</code></span>
                <span><code>        self.dict_finished = {}</code></span>
                <span><code>        self.dict_sorted = {}</code></span>
                <span><code></code></span>
                <span><code>    def append(self, column, mode, middle_target=None, district=None):</code></span>
                <span><code>        """</code></span>
                <span><code>        :param mode 'max'   'min'   'middle'    'district'</code></span>
                <span><code>        """</code></span>
                <span><code>        df = self.file[column]</code></span>
                <span><code></code></span>
                <span><code>        def standard(df):</code></span>
                <span><code>            num = 0</code></span>
                <span><code>            for a in list(df):</code></span>
                <span><code>                num += a ** 2</code></span>
                <span><code>            num = sqrt(num)</code></span>
                <span><code>            return pd.Series(a / num for a in list(df))</code></span>
                <span><code></code></span>
                <span><code>        if mode == "max":</code></span>
                <span><code>            df = standard(df)</code></span>
                <span><code>            self.file[f'{column}_finished'] = df</code></span>
                <span><code>            self.finished.append(f'{column}_finished')</code></span>
                <span><code>        elif mode == 'min':</code></span>
                <span><code>            sum = max(list(df))</code></span>
                <span><code>            df = standard(pd.Series([(sum - a) for a in list(df)]))</code></span>
                <span><code>            self.file[f'{column}_finished'] = df</code></span>
                <span><code>            self.finished.append(f'{column}_finished')</code></span>
                <span><code>        elif mode == 'middle':</code></span>
                <span><code>            df = pd.Series([(abs(a - middle_target)) for a in list(df)])</code></span>
                <span><code>            sum = max(list(df))</code></span>
                <span><code>            df = standard(pd.Series([(sum - a) for a in list(df)]))</code></span>
                <span><code>            self.file[f'{column}_finished'] = df</code></span>
                <span><code>            self.finished.append(f'{column}_finished')</code></span>
                <span><code>        elif mode == 'district':</code></span>
                <span><code>            mini = min(list(df))</code></span>
                <span><code>            maxi = max(list(df))</code></span>
                <span><code>            M = max(district[0] - mini, maxi - district[1])</code></span>
                <span><code></code></span>
                <span><code>            def transfer(num):</code></span>
                <span><code>                if num < district[0]:</code></span>
                <span><code>                    return 1 - (district[0] - num) / M</code></span>
                <span><code>                elif num > district[1]:</code></span>
                <span><code>                    return 1 - (num - district[1]) / M</code></span>
                <span><code>                else:</code></span>
                <span><code>                    return 1</code></span>
                <span><code></code></span>
                <span><code>            df = standard(pd.Series([transfer(a) for a in list(df)]))</code></span>
                <span><code>            self.file[f'{column}_finished'] = df</code></span>
                <span><code>            self.finished.append(f'{column}_finished')</code></span>
                <span><code></code></span>
                <span><code>    def remove(self, column):</code></span>
                <span><code>        self.finished.remove(column)</code></span>
                <span><code></code></span>
                <span><code>    def evaluate(self, type_name):</code></span>
                <span><code>        maxs = []</code></span>
                <span><code>        mins = []</code></span>
                <span><code>        for a in self.finished:</code></span>
                <span><code>            maxs.append(max(self.file[a]))</code></span>
                <span><code>            mins.append(min(self.file[a]))</code></span>
                <span><code></code></span>
                <span><code>        def distance(lst1, lst2):</code></span>
                <span><code>            num = 0</code></span>
                <span><code>            for a, b in zip(lst1, lst2):</code></span>
                <span><code>                num += (a - b) ** 2</code></span>
                <span><code>            return sqrt(num)</code></span>
                <span><code></code></span>
                <span><code>        points = []</code></span>
                <span><code>        names = []</code></span>
                <span><code>        for a in range(len(self.file[type_name])):</code></span>
                <span><code>            names.append(self.file[type_name][a])</code></span>
                <span><code>            points.append(list(np.array(self.file.loc[[a], self.finished])[0]))</code></span>
                <span><code>        dict = {}</code></span>
                <span><code>        for a, b in zip(names, points):</code></span>
                <span><code>            dict[a] = distance(b, mins) / (distance(b, maxs) + distance(b, mins))</code></span>
                <span><code>        num = sum(dict.values())</code></span>
                <span><code>        for a, b in zip(dict.keys(), dict.values()):</code></span>
                <span><code>            dict[a] = b / num</code></span>
                <span><code>        self.dict_finished = dict</code></span>
                <span><code>        return dict</code></span>
                <span><code></code></span>
                <span><code>    def clear(self):</code></span>
                <span><code>        self.dict_finished = {}</code></span>
                <span><code>        self.dict_sorted = {}</code></span>
                <span><code></code></span>
                <span><code>    def sort(self):</code></span>
                <span><code>        names = list(self.dict_finished.keys())</code></span>
                <span><code>        points = list(self.dict_finished.values())</code></span>
                <span><code>        for a in range(len(names) - 1):</code></span>
                <span><code>            for b in range(a + 1, len(names)):</code></span>
                <span><code>                if points[a] < points[b]:</code></span>
                <span><code>                    temp = points[a]</code></span>
                <span><code>                    points[a] = points[b]</code></span>
                <span><code>                    points[b] = temp</code></span>
                <span><code>                    temp = names[a]</code></span>
                <span><code>                    names[a] = names[b]</code></span>
                <span><code>                    names[b] = temp</code></span>
                <span><code>        dict = {}</code></span>
                <span><code>        for a, b in zip(names, points):</code></span>
                <span><code>            dict[a] = b</code></span>
                <span><code>        self.dict_sorted = dict</code></span>
                <span><code>        return dict</code></span>
            </pre>
        </li>
        <li>
            <div>实例求解</div>
            <div>数据如下：</div>
            <table border="4">
                <tr>
                    <th>River</th>
                    <th>oxygen</th>
                    <th>PH</th>
                    <th>bacteria</th>
                    <th>waterplants</th>
                </tr>
                <tr>
                    <td>A</td>
                    <td>0.84</td>
                    <td>3</td>
                    <td>14634</td>
                    <td>4317</td>
                </tr>
                <tr>
                    <td>B</td>
                    <td>0.37</td>
                    <td>2</td>
                    <td>4583</td>
                    <td>460</td>
                </tr>
                <tr>
                    <td>C</td>
                    <td>0.65</td>
                    <td>4</td>
                    <td>9301</td>
                    <td>2563</td>
                </tr>
                <tr>
                    <td>D</td>
                    <td>0.22</td>
                    <td>8</td>
                    <td>14616</td>
                    <td>887</td>
                </tr>
                <tr>
                    <td>E</td>
                    <td>0.09</td>
                    <td>9</td>
                    <td>3700</td>
                    <td>1170</td>
                </tr>
                <tr>
                    <td>F</td>
                    <td>0.74</td>
                    <td>1</td>
                    <td>395</td>
                    <td>2610</td>
                </tr>
                <tr>
                    <td>G</td>
                    <td>0.43</td>
                    <td>11</td>
                    <td>3706</td>
                    <td>1489</td>
                </tr>
                <tr>
                    <td>H</td>
                    <td>0.88</td>
                    <td>2</td>
                    <td>3930</td>
                    <td>4988</td>
                </tr>
                <tr>
                    <td>I</td>
                    <td>0.25</td>
                    <td>8</td>
                    <td>18772</td>
                    <td>3439</td>
                </tr>
                <tr>
                    <td>J</td>
                    <td>0.87</td>
                    <td>5</td>
                    <td>18013</td>
                    <td>4549</td>
                </tr>
                <tr>
                    <td>K</td>
                    <td>0.26</td>
                    <td>5</td>
                    <td>5269</td>
                    <td>2600</td>
                </tr>
                <tr>
                    <td>L</td>
                    <td>0.41</td>
                    <td>2</td>
                    <td>2774</td>
                    <td>2846</td>
                </tr>
                <tr>
                    <td>M</td>
                    <td>0.53</td>
                    <td>9</td>
                    <td>14141</td>
                    <td>3820</td>
                </tr>
                <tr>
                    <td>N</td>
                    <td>0.23</td>
                    <td>11</td>
                    <td>786</td>
                    <td>2527</td>
                </tr>
            </table>
            <pre id="code_block">
                <span><code>data = pd.read_csv("water.csv")</code></span>
                <span><code>topsis = TOPSIS(data)</code></span>
                <span><code>topsis.append('waterplants', 'district', district=[500, 1000])</code></span>
                <span><code>topsis.append('oxygen','max')</code></span>
                <span><code>topsis.append('PH','middle',middle_target=7)</code></span>
                <span><code>topsis.append('bacteria','min')</code></span>
                <span><code>topsis.evaluate('River')</code></span>
                <span><code>topsis.sort()</code></span>
                <span><code>print(topsis.dict_sorted)</code></span>
            </pre>
            <div>结果如下：</div>
            <div>{'G': 0.0818402297874214, 'E': 0.0813325358570309, 'C': 0.0809361664748927, 'K': 0.0782292415468525, 'D': 0.0772586744230196, 'B': 0.0745489156224116, 'F': 0.0737510000691358, 'N': 0.0716558654660967, 'L': 0.0665053239819720, 'J': 0.0651650850235762, 'M': 0.0647876782651021, 'H': 0.0646685161574278, 'I': 0.0602932909811161, 'A': 0.0590274763439446}</div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">LinearRegression线性回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>线性回归模型</div>
            <div><img src="../static/Math/mathematicalModeling/94.png"></div>
            <div>损失函数</div>
            <div><img src="../static/Math/mathematicalModeling/95.png"></div>
            <div>梯度下降训练</div>
            <div><img src="../static/Math/mathematicalModeling/96.png"></div>
        </li>
        <li>
            <div>代码实现</div>
            <ul type="disc">
                <li>
                    <div>单变量</div>
                    <div>导入数据</div>
                    <pre id="code_block">
                        <span><code>import pandas as pd</code></span>
                        <span><code>df = pd.read_csv('world-happiness-report-2017.csv')</code></span>
                        <span><code>y = df[['Happiness.Score']].values</code></span>
                        <span><code>x = df[['Economy..GDP.per.Capita.']].values</code></span>
                        <span><code></code></span>
                        <span><code>from sklearn.model_selection import train_test_split</code></span>
                        <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
                    </pre>
                    <div>开始训练</div>
                    <pre id="code_block">
                        <span><code>from sklearn.model_selection import cross_val_score</code></span>
                        <span><code>from sklearn.linear_model import LinearRegression</code></span>
                        <span><code></code></span>
                        <span><code>lr = LinearRegression()</code></span>
                        <span><code>lr.fit(xtrain,ytrain)</code></span>
                        <span><code>print('b:',lr.intercept_)</code></span>
                        <span><code>print('w',lr.coef_)</code></span>
                        <span><code>print('mse',cross_val_score(lr,xtrain,ytrain,cv=10).mean())</code></span>
                    </pre>
                    <div>结果如下：</div>
                    <div>b: [3.18243203]</div>
                    <div>w [[2.26404324]]</div>
                    <div>mse 0.4562094339350504</div>
                    <div>可视化</div>
                    <pre id="code_block">
                        <span><code>import matplotlib.pyplot as plt</code></span>
                        <span><code>plt.xlabel('Economy..GDP.per.Capita.')</code></span>
                        <span><code>plt.ylabel('Happiness.Score')</code></span>
                        <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                        <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                        <span><code>d = np.linspace(0,1.75,50)</code></span>
                        <span><code>plt.plot(d,lr.predict(d.reshape(-1,1)),c='r')</code></span>
                        <span><code>plt.legend()</code></span>
                        <span><code>plt.show()</code></span>
                    </pre>
                    <div><img src="../static/Math/mathematicalModeling/97.png"></div>
                </li>
                <li>
                    <div>多变量</div>
                    <div>数据导入只需修改</div>
                    <pre id="code_block">
                        <span><code>x = df[['Economy..GDP.per.Capita.','Health..Life.Expectancy.']]</code></span>
                    </pre>
                    <div>结果如下：</div>
                    <div>结果如下：</div>
                    <div>b: [3.02154144]</div>
                    <div>w [[1.33088889 1.85014173]]</div>
                    <div>mse 0.334704357723213</div>
                </li>
            </ul>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">KNN K近邻回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>KNN算法</div>
            <div><img src="../static/Math/mathematicalModeling/98.png"></div>
            <div>绿色和蓝色是已知数据，根据已知数据，我们想要知道，红色的点属于哪一类。</div>
            <div>这是，我们选择的方法是：看距离红色最近的一个点（K=1）是属于哪一类，或者看距离红色最近的两个个点（K=1）或三个点（K=3）是属于哪一类，此时，我们需要在这些点里做投票，看看这个区域内，哪个颜色的点数量多。</div>
        </li>
        <li>
            <div>注意</div>
            <div>特征中量纲差距过大，导致其中一个或几个特征在计算中基本起不到作用，这是我们需要特征的缩放。</div>
            <div>线性归一化/标准化</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1,1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).reshape(-1,1)</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>标准化</div>
            <pre id="code_block">
                <span><code>from sklearn.preprocessing import StandardScaler</code></span>
                <span><code>x_std = StandardScaler()</code></span>
                <span><code>xtrain = x_std.fit_transform(xtrain)</code></span>
                <span><code>y_std = StandardScaler()</code></span>
                <span><code>ytrain = y_std.fit_transform(ytrain)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.neighbors import KNeighborsRegressor</code></span>
                <span><code></code></span>
                <span><code>knr = KNeighborsRegressor()</code></span>
                <span><code>knr.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(knr,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 0.023608694399218304</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>d = np.linspace(-2,2,1000).reshape(-1,1)</code></span>
                <span><code>y_pred = knr.predict(d.reshape(-1,1))</code></span>
                <span><code>d = x_std.inverse_transform(d)</code></span>
                <span><code>y_pred = y_std.inverse_transform(y_pred)</code></span>
                <span><code>xtrain = x_std.inverse_transform(xtrain)</code></span>
                <span><code>ytrain = y_std.inverse_transform(ytrain)</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>plt.plot(d,y_pred,c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/99.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">SVR支持向量机回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>支持向量机算法</div>
            <div>SVM与logistic分类器类似，也是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。</div>
            <div>对于下面一个数据集，有两类分别使用×和○来表示。那么我们想要找到一条曲线来区分这两类。可想而知，这样的曲线存在无数条，如何找到那一条最优的曲线呢？那就是要找到间隔（Gap）最大的那一条曲线，然后我们就可以根据这条曲线来分类了。而这条曲线，我们称为超平面。图中加粗的×与○，我们则称这些向量为支持向量。</div>
            <div><img src="../static/Math/mathematicalModeling/100.png"></div>
            <div>而实际上，我们很少会遇到上面的情况，能直接使用一条直线将数据分类，更多的时候，数据无法通过直线来分类。比如下面这种情况：</div>
            <div><img src="../static/Math/mathematicalModeling/101.png"></div>
            <div>当然了，这都不是事，既然在二维上该数据无法使用线性分类，那我们就将数据映射到更高维上，在高维上构造超平面，从而完成分类。</div>
            <div><img src="../static/Math/mathematicalModeling/102.png"></div>
            <div>这就是为什么将上面的直线称为超平面。</div>
            <div>所以对于非线性的模型，我们需要：</div>
            <ol type="i">
                <li>使用非线性映射将数据投影至特征空间；</li>
                <li>在特征空间使用线性分类器；</li>
            </ol>
            <div>看似很简单，但是我们在映射时，就会发现当变量增多时，映射到高维空间的维度是呈指数增长的，计算起来十分困难，这时候就需要核函数（kernel function）了。核函数也是将特征从低维到高维进行转换，但是它是先在低维上进行计算，实际的分类效果表现在高维上。这样，我们就避免了在高维上复杂的计算，仍得到相同的结果。</div>
            <div>一些常用的核函数：</div>
            <ul type="disc">
                <li>多项式核</li>
                <li>高斯核</li>
                <li>线性核</li>
            </ul>
            <div>SVR是要找出一个超平面，使得所有数据到这个超平面的距离最小。</div>
            <div><img src="../static/Math/mathematicalModeling/103.png"></div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1,1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.svm import SVR</code></span>
                <span><code>svr = SVR()</code></span>
                <span><code>svr.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(svr,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 4.376258150076342</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('Economy..GDP.per.Capita.')</code></span>
                <span><code>plt.ylabel('Happiness.Score')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,svr.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/104.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">Ridge岭回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>岭回归算法</div>
            <div>实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价获得回归系数更为符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。</div>
            <div><img src="../static/Math/mathematicalModeling/105.png"></div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import pandas as pd</code></span>
                <span><code>df = pd.read_csv('world-happiness-report-2017.csv')</code></span>
                <span><code>y = df[['Happiness.Score']].values</code></span>
                <span><code>x = df[['Economy..GDP.per.Capita.']].values</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.linear_model import Ridge</code></span>
                <span><code>ridge = Ridge()</code></span>
                <span><code>ridge.fit(xtrain,ytrain)</code></span>
                <span><code>print('intercept',ridge.intercept_)</code></span>
                <span><code>print('coef',ridge.coef_)</code></span>
                <span><code>print('mse',-cross_val_score(ridge,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>intercept [3.35416377]</div>
            <div>coef [[2.03464087]]</div>
            <div>mse 0.48136721864464976</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,2,100)</code></span>
                <span><code>plt.plot(d,ridge.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/106.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">Lasso回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>Lasso回归算法</div>
            <div>与ridge回归相似</div>
            <div>惩罚项不同</div>
            <div><img src="../static/Math/mathematicalModeling/107.png"></div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import pandas as pd</code></span>
                <span><code>df = pd.read_csv('world-happiness-report-2017.csv')</code></span>
                <span><code>y = df[['Happiness.Score']].values</code></span>
                <span><code>x = df[['Economy..GDP.per.Capita.']].values</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.linear_model import Lasso</code></span>
                <span><code>lasso = Lasso()</code></span>
                <span><code>lasso.fit(xtrain,ytrain)</code></span>
                <span><code>print('intercept',lasso.intercept_)</code></span>
                <span><code>print('coef',lasso.coef_)</code></span>
                <span><code>print('mse',-cross_val_score(lasso,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>intercept [5.34622034]</div>
            <div>coef [0.]</div>
            <div>mse 1.5643626544971814</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,2,100)</code></span>
                <span><code>plt.plot(d,lasso.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/108.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">MLP多层感知机回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>MLP算法</div>
            <div>MLP是一种常用的前馈神经网络，使用了BP算法的MLP可以被称为BP神经网络。MLP的隐节点采用输入向量与权向量的内积作为激活函数的自变量，激活函数采用Relu函数。各参数对网络的输出具有同等地位的影响，因此MLP是对非线性映射的全局逼近。</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1, 1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.neural_network import MLPRegressor</code></span>
                <span><code>mlp = MLPRegressor(max_iter=10000)</code></span>
                <span><code>mlp.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(mlp,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 0.9478246625545512</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,mlp.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/109.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">DecisionTree决策树回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>DecisionTree算法</div>
            <div>决策树是一个预测模型，它代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。</div>
            <div>一个决策树包含三种类型的节点：</div>
            <ul type="disc">
                <li>决策节点：通常用矩形框来表示</li>
                <li>机会节点：通常用圆圈来表示</li>
                <li>终结节点：通常用三角形来表示</li>
            </ul>
            <div><img src="../static/Math/mathematicalModeling/110.png"></div>
            <div>决策树是一树状结构，它的每一个叶节点对应着一个分类，非叶节点对应着在某个属性上的划分，根据样本在该属性上的不同取值将其划分成若干个子集。对于非纯的叶节点，多数类的标号给出到达这个节点的样本所属的类。构造决策树的核心问题是在每一步如何选择适当的属性对样本做拆分。对一个分类问题，从已知类标记的训练样本中学习并构造出决策树是一个自上而下，分而治之的过程。</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1, 1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.tree import DecisionTreeRegressor</code></span>
                <span><code>dtr = DecisionTreeRegressor(max_depth=5)</code></span>
                <span><code>dtr.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(dtr,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 1.364876322693921</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,dtr.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/111.png"></div>
        </li>
    </ol>'
    <div class="tit">
        <span style="color:red;font-size:40px;">ExtraTrees极端随机树回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>ExtraTrees算法</div>
            <div>RandomForest的一个变种</div>
            <ul type="disc">
                <li>对于每个决策树的训练集，RF采用的是随机采样bootstrap来选择采样集作为每个决策树的训练集，而extra trees一般不采用随机采样，即每个决策树采用原始训练集。</li>
                <li>在选定了划分特征后，RF的决策树会基于基尼系数，均方差之类的原则，选择一个最优的特征值划分点，这和传统的决策树相同。但是extra trees比较的激进，他会随机的选择一个特征值来划分决策树。</li>
            </ul>
            <div>从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于RF所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏差相对于RF进一步增大。在某些时候，extra trees的泛化能力比RF更好。</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1, 1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.ensemble import ExtraTreesRegressor</code></span>
                <span><code>etr = ExtraTreesRegressor(max_depth=5,bootstrap=True,ccp_alpha=0.5)</code></span>
                <span><code>etr.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(etr,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 1.016506085266548</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,etr.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/112.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">RandomForest随机森林回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>Bagging算法</div>
            <div>Bagging是并行式集成学习方法最著名的代表。它直接基于自助采样法(bootstrap sampling)。给定包含m个样本的数据集，我们先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m轮随机采样，我们得到m个样本的采样集，初始训练集中有的样本在采样集中多次出现，有的则从未出现，约63.2%的样本出现在采样集中，而未出现的约36.8%的样本可用作验证集来对后续的泛化性能进行“包外估计”。</div>
            <div>照这样，我们可以采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，然后将这些基学习器进行结合。在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法，这就是Bagging的基本流程。</div>
            <div><img src="../static/Math/mathematicalModeling/113.png"></div>
            <div>RandomForest是Bagging的一种</div>
            <div>主要特点是：</div>
            <ul type="disc">
                <li>个体学习器为决策树</li>
                <li>对训练样本进行采样</li>
                <li>对属性进行随机采样</li>
            </ul>
            <div>从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于RF所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏差相对于RF进一步增大。在某些时候，extra trees的泛化能力比RF更好。</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1, 1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.ensemble import RandomForestRegressor</code></span>
                <span><code>rfr = RandomForestRegressor(max_depth=5)</code></span>
                <span><code>rfr.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(rfr,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 1.7358000800837174</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,rfr.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/114.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">AdaBoost自适应增强回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>Boosting算法</div>
            <div>Boosting是一族可将弱学习器提升为强学习器的算法。它的基本原理：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，提高被错误分类的样本的权重，降低被正确分类的样本的权重，使得先前基学习器做错的训练样本在后续受到更多的关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最后将这T个基学习器进行加权结合。</div>
            <div><img src="../static/Math/mathematicalModeling/115.png"></div>
            <div>AdaBoost是boosting的一种</div>
            <div>有以下三个步骤：</div>
            <ol type="i">
                <li>首先，是初始化训练数据的权值分布D1。假设有N个训练样本数据，则每一个训练样本最开始时，都被赋予相同的权值：w1=1/N。</li>
                <li>然后，训练弱分类器hi。具体训练过程中是：如果某个训练样本点，被弱分类器hi准确地分类，那么在构造下一个训练集中，它对应的权值要减小；相反，如果某个训练样本点被错误分类，那么它的权值就应该增大。权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。</li>
                <li>最后，将各个训练得到的弱分类器组合成一个强分类器。各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，而降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。</li>
            </ol>
            <div>换而言之，误差率低的弱分类器在最终分类器中占的权重较大，否则较小。</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1, 1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.ensemble import AdaBoostRegressor</code></span>
                <span><code>abr = AdaBoostRegressor()</code></span>
                <span><code>abr.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(abr,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 1.8707826549473012</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,abr.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/116.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">GBDT梯度提升树回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>GradientBoost是boosting的一种</div>
            <div>GradientBoost把所有树的结论累加起来得出最终结论的，其核心在于，每一棵树学的是之前所有树结论之和的残差。比如A的真实年龄是18岁，第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶节点，那么累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学习。</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1, 1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.ensemble import GradientBoostingRegressor</code></span>
                <span><code>gbr = GradientBoostingRegressor()</code></span>
                <span><code>gbr.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(gbr,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 1.4216151397411787</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,gbr.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/117.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">Bagging装袋回归</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见RandomForest</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import numpy as np</code></span>
                <span><code>x = np.linspace(0,5,100).reshape(-1, 1)</code></span>
                <span><code>y = (x**2+np.random.randn(100,1)).ravel()</code></span>
                <span><code>from sklearn.model_selection import train_test_split</code></span>
                <span><code>xtrain,xtest,ytrain,ytest = train_test_split(x,y)</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>from sklearn.ensemble import BaggingRegressor</code></span>
                <span><code>br = BaggingRegressor()</code></span>
                <span><code>br.fit(xtrain,ytrain)</code></span>
                <span><code>print('mse',-cross_val_score(br,xtrain,ytrain,cv=10,scoring='neg_mean_squared_error').mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>mse 1.486465002193159</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>plt.xlabel('X')</code></span>
                <span><code>plt.ylabel('y')</code></span>
                <span><code>plt.scatter(xtrain,ytrain,c='b',label='train')</code></span>
                <span><code>plt.scatter(xtest,ytest,c='g',label='test')</code></span>
                <span><code>d = np.linspace(0,5,100)</code></span>
                <span><code>plt.plot(d,br.predict(d.reshape(-1,1)),c='r')</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/118.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">KNN K近邻分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见KNN K近邻回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.neighbors import KNeighborsClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>knc = KNeighborsClassifier()</code></span>
                <span><code>knc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(knc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.885</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(knc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/119.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">逻辑回归分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>Logistic 分布是一种连续型的概率分布，其分布函数和密度函数分别为：</div>
            <div><img src="../static/Math/mathematicalModeling/120.png"></div>
            <div>在Logistic回归中，我们不像线性回归那样直接将直线拟合到我们的数据。取而代之的是，我们将一条称为Sigmoid的S形曲线拟合到我们的观测结果中。</div>
            <div><img src="../static/Math/mathematicalModeling/121.png"></div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.neighbors import LogisticRegression</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>lr = LogisticRegression()</code></span>
                <span><code>lr.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(rc.coef_)</code></span>
                <span><code>print(rc.intercept_)</code></span>
                <span><code>print(cross_val_score(lr,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>系数 [[ 2.21423171 -2.00793047]]</div>
            <div>截距 [-1.06286487]</div>
            <div>accuracy 0.93</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(lr,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/122.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">Ridge岭回归分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见Ridge岭回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.neighbors import RidgeClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>rc = RidgeClassifier()</code></span>
                <span><code>rc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(rc.coef_)</code></span>
                <span><code>print(rc.intercept_)</code></span>
                <span><code>print(cross_val_score(rc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>系数 [[ 0.35855341 -0.31699953]]</div>
            <div>截距 [-0.16783206]</div>
            <div>accuracy 0.93</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(rc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/123.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">RandomForest随机森林分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见RandomForest随机森林回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.ensemble import RandomForestClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>rfc = RandomForestClassifier()</code></span>
                <span><code>rfc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(rfc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.905</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(rfc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/124.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">DecisionTree决策树分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见DecisionTree决策树回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.tree import DecisionTreeClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>dtc = DecisionTreeClassifier()</code></span>
                <span><code>dtc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(dtc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.8549999999999999</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(dtc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/125.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">ExtraTrees极端随机树分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见ExtraTrees极端随机树回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.ensemble import ExtraTreesClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>etc = ExtraTreesClassifier()</code></span>
                <span><code>etc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(etc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.925</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(etc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/126.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">GBDT梯度提升树分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见GBDT梯度提升回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.ensemble import GradientBoostingClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>gbc = GradientBoostingClassifier()</code></span>
                <span><code>gbc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(gbc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.915</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(gbc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/127.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">AdaBoost自适应增强分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见AdaBoost自适应增强回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.ensemble import AdaBoostClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>abc = AdaBoostClassifier()</code></span>
                <span><code>abc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(abc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.8800000000000001</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(abc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/128.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">SVC支持向量机分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见SVR支持向量机回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.SVR import SVR</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>svr = SVR()</code></span>
                <span><code>svr.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(svr,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.1275525062237303</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(svr,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/129.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">MLP多层感知机分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见MLP多层感知机回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.neural_network import MLPClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>mlpc = MLPClassifier(max_iter=2000)</code></span>
                <span><code>mlpc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(mlpc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.915</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(mlpc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/130.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">Bagging装袋分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见Bagging装袋回归</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.ensemble import BaggingClassifier</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>bc = BaggingClassifier()</code></span>
                <span><code>bc.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(bc,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.885</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(bc,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/131.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">朴素贝叶斯分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>Naive Bayes算法</div>
            <div><img src="../static/Math/mathematicalModeling/132.png"></div>
            <div>GaussianNB、MultinomialNB、BernoulliNB，分别是高斯朴素贝叶斯、多项式分布朴素贝叶斯和伯努利朴素贝叶斯。多项式分布是将重复词语是为其重复多次，伯努利朴素贝叶斯是将重复的词语视为其只出现1次</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.naive_bayes import GaussianNB</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>bayes = GaussianNB()</code></span>
                <span><code>bayes.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(bayes,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>Gaussian 0.9100000000000001</div>
            <div>Bernoulli 0.5</div>
            <div>Multinomial 0.9099999999999999</div>
            <div>Complement 0.8800000000000001</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(bayes,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div>Gaussian</div>
            <div><img src="../static/Math/mathematicalModeling/133.png"></div>
            <div>Bernoulli</div>
            <div><img src="../static/Math/mathematicalModeling/134.png"></div>
            <div>Multinomial</div>
            <div><img src="../static/Math/mathematicalModeling/135.png"></div>
            <div>Complement</div>
            <div><img src="../static/Math/mathematicalModeling/136.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">LDA线性判断分析分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>线性判别分析是一种很重要的分类算法，同时也是一种降维方法（这个我还没想懂）。和PCA一样，LDA也是通过投影的方式达到去除数据之间冗余的一种算法。如下图所示的2类数据，为了正确的分类，我们希望这2类数据投影之后，同类的数据尽可能的集中（距离近，有重叠），不同类的数据尽可能的分开（距离远，无重叠），左图的投影不好，因为2类数据投影后有重叠，而右图投影之后可以很好地进行分类，因为投影之后的2类数据之间几乎没有重叠，只是类内重叠得很厉害，而这正是我们想要的结果。</div>
            <div><img src="../static/Math/mathematicalModeling/137.png"></div>
            <div><img src="../static/Math/mathematicalModeling/139.png"></div>
            <div><img src="../static/Math/mathematicalModeling/140.png"></div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>lda = LinearDiscriminantAnalysis()</code></span>
                <span><code>lda.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(lda,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.8800000000000001</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(lda,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/138.png"></div>
        </li>
    </ol>
    <div class="tit">
        <span style="color:red;font-size:40px;">QDA二次判别分析分类</span>
    </div>
    <ol type="I">
        <li>
            <div>原理讲解</div>
            <div>见LDA</div>
        </li>
        <li>
            <div>代码实现</div>
            <div>导入数据</div>
            <pre id="code_block">
                <span><code>import matplotlib.pyplot as plt</code></span>
                <span><code>import numpy as np</code></span>
                <span><code>import pandas as pd</code></span>
                <span><code></code></span>
                <span><code>def points_within_circle(radius, center=(0, 0), number_of_points=100):</code></span>
                <span><code>    center_x, center_y = center</code></span>
                <span><code>    r = radius * np.sqrt(np.random.random((number_of_points,)))</code></span>
                <span><code>    theta = np.random.random((number_of_points,)) * 2 * np.pi</code></span>
                <span><code>    x = center_x + r * np.cos(theta)</code></span>
                <span><code>    y = center_y + r * np.sin(theta)</code></span>
                <span><code>    return x, y</code></span>
                <span><code></code></span>
                <span><code>X = np.arange(0, 8)</code></span>
                <span><code>point1_x, point1_y = points_within_circle(2, (3, 5), 100)</code></span>
                <span><code>point2_x, point2_y = points_within_circle(2, (5, 3), 100)</code></span>
                <span><code>x = np.concatenate((point1_x,point2_x))</code></span>
                <span><code>y = np.concatenate((point1_y,point2_y))</code></span>
                <span><code>cls = np.array([0]*100+[1]*100)</code></span>
                <span><code>df = pd.DataFrame({'x':x,'y':y,'target':cls})</code></span>
            </pre>
            <div>开始训练</div>
            <pre id="code_block">
                <span><code>from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis</code></span>
                <span><code>from sklearn.model_selection import cross_val_score</code></span>
                <span><code>qda = LinearDiscriminantAnalysis()</code></span>
                <span><code>qda.fit(df[['x','y']].values,df['target'].values)</code></span>
                <span><code>print(cross_val_score(qda,df[['x','y']].values,df['target'].values,cv=5).mean())</code></span>
            </pre>
            <div>结果如下：</div>
            <div>accuracy 0.9049999999999999</div>
            <div>可视化</div>
            <pre id="code_block">
                <span><code>def plot_decision_boundary(model, axis):</code></span>
                <span><code>    x0, x1 = np.meshgrid(</code></span>
                <span><code>        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),</code></span>
                <span><code>        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),</code></span>
                <span><code>    )</code></span>
                <span><code>    X_new = np.c_[x0.ravel(), x1.ravel()]</code></span>
                <span><code></code></span>
                <span><code>    y_predict = model.predict(X_new)</code></span>
                <span><code>    zz = y_predict.reshape(x0.shape)</code></span>
                <span><code></code></span>
                <span><code>    from matplotlib.colors import ListedColormap</code></span>
                <span><code>    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])</code></span>
                <span><code></code></span>
                <span><code>    plt.contourf(x0, x1, zz, cmap=custom_cmap)</code></span>
                <span><code></code></span>
                <span><code>plot_decision_boundary(qda,axis=[1,7,1,8])</code></span>
                <span><code>plt.scatter(point1_x, point1_y, c="red", label="class 1")</code></span>
                <span><code>plt.scatter(point2_x, point2_y, c="black", label="class 2")</code></span>
                <span><code>plt.legend()</code></span>
                <span><code>plt.grid()</code></span>
                <span><code>plt.show()</code></span>
            </pre>
            <div><img src="../static/Math/mathematicalModeling/142.png"></div>
        </li>
    </ol>

</body>
</html>